{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7016635,"sourceType":"datasetVersion","datasetId":4006737,"isSourceIdPinned":true}],"dockerImageVersionId":30580,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n!pip install \"numpy>=1.12.1\"\n!pip install \"scipy>=1.0.1\"\n!pip install \"torch>=2.0.0\"\n!pip install accelerate==0.23.0\n!pip install bitsandbytes\n!pip install peft==0.5.0\n!pip install transformers==4.34.0\n!pip install datasets\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T19:25:22.191214Z","iopub.execute_input":"2024-10-04T19:25:22.191889Z","iopub.status.idle":"2024-10-04T19:27:15.477023Z","shell.execute_reply.started":"2024-10-04T19:25:22.191854Z","shell.execute_reply":"2024-10-04T19:27:15.475979Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy>=1.12.1 in /opt/conda/lib/python3.10/site-packages (1.24.3)\nRequirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (1.11.3)\nRequirement already satisfied: numpy<1.28.0,>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from scipy>=1.0.1) (1.24.3)\nRequirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.10/site-packages (2.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.0.0) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.0.0) (1.3.0)\nCollecting accelerate==0.23.0\n  Obtaining dependency information for accelerate==0.23.0 from https://files.pythonhosted.org/packages/d9/92/2d3aecf9f4a192968035880be3e2fc8b48d541c7128f7c936f430d6f96da/accelerate-0.23.0-py3-none-any.whl.metadata\n  Downloading accelerate-0.23.0-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.23.0) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.23.0) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.23.0) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.23.0) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.23.0) (2.0.0)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate==0.23.0) (0.17.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate==0.23.0) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.23.0) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.23.0) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.23.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.23.0) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.23.0) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.23.0) (2023.10.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.23.0) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.23.0) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.23.0) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.23.0) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.23.0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.23.0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.23.0) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.23.0) (1.3.0)\nDownloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.24.1\n    Uninstalling accelerate-0.24.1:\n      Successfully uninstalled accelerate-0.24.1\nSuccessfully installed accelerate-0.23.0\nCollecting bitsandbytes\n  Obtaining dependency information for bitsandbytes from https://files.pythonhosted.org/packages/e4/e6/ccb84da7ffaf208a71c2c3c8e1120b34759df640db959660be9a98505eb4/bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata\n  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.0.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.24.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nDownloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.44.1\nCollecting peft==0.5.0\n  Obtaining dependency information for peft==0.5.0 from https://files.pythonhosted.org/packages/37/1a/8d20e8704da9fa070eb909265584b960da57be1d833d550c59f50906dc5c/peft-0.5.0-py3-none-any.whl.metadata\n  Downloading peft-0.5.0-py3-none-any.whl.metadata (22 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (6.0.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (2.0.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (4.35.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (4.66.1)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (0.23.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (0.4.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft==0.5.0) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0) (3.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate->peft==0.5.0) (0.17.3)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.5.0) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.5.0) (2.31.0)\nRequirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.5.0) (0.14.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate->peft==0.5.0) (2023.10.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.5.0) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.5.0) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.5.0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.5.0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.5.0) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.5.0) (1.3.0)\nDownloading peft-0.5.0-py3-none-any.whl (85 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.5.0\nCollecting transformers==4.34.0\n  Obtaining dependency information for transformers==4.34.0 from https://files.pythonhosted.org/packages/1a/d1/3bba59606141ae808017f6fde91453882f931957f125009417b87a281067/transformers-4.34.0-py3-none-any.whl.metadata\n  Downloading transformers-4.34.0-py3-none-any.whl.metadata (121 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.5/121.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0) (0.17.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0) (2.31.0)\nRequirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0) (0.14.1)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0) (0.4.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.0) (2023.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.0) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.34.0) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.34.0) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.34.0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.34.0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.34.0) (2023.7.22)\nDownloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.35.0\n    Uninstalling transformers-4.35.0:\n      Successfully uninstalled transformers-4.35.0\nSuccessfully installed transformers-4.34.0\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.24.3)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.10.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.5)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.17.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'\\n!pip install zstandard\\n!pip install jsonlines\\n!pip install sentencepiece\\n!pip install fire\\n!pip install datasketch==1.5.9\\n!pip install nltk==3.8.1\\n!pip install scikit-learn==1.3.0\\n!pip install pytest'"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom peft import PeftModel, PeftConfig\nfrom peft import AutoPeftModelForCausalLM\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForTokenClassification, AutoConfig, GenerationConfig\nfrom transformers import Trainer, TrainingArguments, logging, TrainerCallback, TrainerState, TrainerControl, BitsAndBytesConfig\nfrom transformers.trainer_utils import PREFIX_CHECKPOINT_DIR\nfrom peft import get_peft_model, LoraConfig, prepare_model_for_kbit_training\nimport torch.nn.functional as F\nfrom datasets import load_dataset\nimport time\nfrom typing import Any, List, Mapping, Optional\nimport transformers\nimport os\nfrom pathlib import Path","metadata":{"execution":{"iopub.status.busy":"2024-10-04T19:27:23.624639Z","iopub.execute_input":"2024-10-04T19:27:23.625001Z","iopub.status.idle":"2024-10-04T19:27:41.938390Z","shell.execute_reply.started":"2024-10-04T19:27:23.624973Z","shell.execute_reply":"2024-10-04T19:27:41.937488Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Загружаем датасет","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset","metadata":{"execution":{"iopub.status.busy":"2024-10-04T19:28:04.371473Z","iopub.execute_input":"2024-10-04T19:28:04.372340Z","iopub.status.idle":"2024-10-04T19:28:04.376555Z","shell.execute_reply.started":"2024-10-04T19:28:04.372310Z","shell.execute_reply":"2024-10-04T19:28:04.375424Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data = load_dataset(\n    \"json\", \n    data_files={'train' : '/kaggle/input/fine-tunning-llama/train.json' , 'validation' : '/kaggle/input/fine-tunning-llama/val.json'}\n)\n\ndata","metadata":{"execution":{"iopub.status.busy":"2024-10-04T19:28:13.073578Z","iopub.execute_input":"2024-10-04T19:28:13.074246Z","iopub.status.idle":"2024-10-04T19:28:13.345186Z","shell.execute_reply.started":"2024-10-04T19:28:13.074204Z","shell.execute_reply":"2024-10-04T19:28:13.344357Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-e727458344e87341/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8dfa2d9080b04403945a42030af97867"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"752a2955e678468f821a572b2f257c7e"}},"metadata":{}},{"name":"stdout","text":"Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-e727458344e87341/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"207d480509b745cdb059e582631adec7"}},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['system', 'user', 'bot'],\n        num_rows: 22\n    })\n    validation: Dataset({\n        features: ['system', 'user', 'bot'],\n        num_rows: 6\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Предобработка датасета","metadata":{}},{"cell_type":"code","source":"print(generate_and_tokenize_prompt(data[\"train\"][0]))","metadata":{"execution":{"iopub.status.busy":"2023-11-28T08:52:39.720681Z","iopub.execute_input":"2023-11-28T08:52:39.721001Z","iopub.status.idle":"2023-11-28T08:52:39.73238Z","shell.execute_reply.started":"2023-11-28T08:52:39.720968Z","shell.execute_reply":"2023-11-28T08:52:39.731596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\nfrom peft import PeftModel, PeftConfig\n\nMODEL_NAME = \"IlyaGusev/saiga2_7b_lora\"\n\n# Определяем устройство\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Загружаем конфигурацию адаптеров\nconfig = PeftConfig.from_pretrained(MODEL_NAME)\n\n# Загружаем базовую модель с квантованием и указываем точное устройство\nmodel = AutoModelForCausalLM.from_pretrained(\n    config.base_model_name_or_path,\n    load_in_8bit=True,  # Загружаем в 8-битной точности\n    torch_dtype=torch.float16,  # Используем float16 для экономии памяти\n    device_map={'': torch.cuda.current_device()}  # Явно указываем устройство\n)\n\n# Подключаем адаптеры для тренировки\nmodel = PeftModel.from_pretrained(\n    model,\n    MODEL_NAME,\n    torch_dtype=torch.float16,\n    is_trainable=True  # Делаем модель обучаемой\n)\n\n# Переводим модель в режим тренировки\nmodel.train()\n\n# Загружаем токенизатор и конфигурацию генерации\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False)\ngeneration_config = GenerationConfig.from_pretrained(MODEL_NAME)\n\n# Печатаем конфигурацию генерации\nprint(generation_config)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T19:30:39.082599Z","iopub.execute_input":"2024-10-04T19:30:39.083314Z","iopub.status.idle":"2024-10-04T19:33:04.472870Z","shell.execute_reply.started":"2024-10-04T19:30:39.083279Z","shell.execute_reply":"2024-10-04T19:33:04.471994Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b72b48dfee54dd8bfa050a9159a142b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00001-of-00002.bin:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48b410cbe10d46618f2c416dcf965664"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00002-of-00002.bin:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4efa717c9b4546edb58d355193fa94b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d47ab11a2e284ad5b8472dfc40a87086"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57c5b35cb25d4b75bec741a10c23c659"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading adapter_model.bin:   0%|          | 0.00/67.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"193f1fb5587544afbd5696844e0c5da6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer_config.json:   0%|          | 0.00/278 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"824a69af637b421ab09032e4e6b70607"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e69d08278c764d2390c0fddc20262b3b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47d2bcbe1e6f4401ab2c233a0a9539cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/118 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4682bd7f17840e28d1c072e8f14573e"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading generation_config.json:   0%|          | 0.00/265 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"751df219125048b985d67ba4bd205af9"}},"metadata":{}},{"name":"stdout","text":"GenerationConfig {\n  \"bos_token_id\": 1,\n  \"do_sample\": true,\n  \"eos_token_id\": 2,\n  \"max_new_tokens\": 3584,\n  \"no_repeat_ngram_size\": 15,\n  \"pad_token_id\": 0,\n  \"repetition_penalty\": 1.2,\n  \"temperature\": 0.5,\n  \"top_k\": 30,\n  \"top_p\": 0.9\n}\n\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data = (\n    data[\"train\"].map(generate_and_tokenize_prompt)\n)\n\nval_data = (\n    data[\"validation\"].map(generate_and_tokenize_prompt)\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T19:33:12.255147Z","iopub.execute_input":"2024-10-04T19:33:12.255896Z","iopub.status.idle":"2024-10-04T19:33:12.409453Z","shell.execute_reply.started":"2024-10-04T19:33:12.255862Z","shell.execute_reply":"2024-10-04T19:33:12.408508Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/22 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"677fea0d34634a94a22a296b3311ada0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5428bb827854ccc9dbc1eda3c43dfd7"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Обучаем модель","metadata":{}},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2024-10-04T19:33:18.775394Z","iopub.execute_input":"2024-10-04T19:33:18.776100Z","iopub.status.idle":"2024-10-04T19:33:18.780156Z","shell.execute_reply.started":"2024-10-04T19:33:18.776066Z","shell.execute_reply":"2024-10-04T19:33:18.779294Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 4\nMICRO_BATCH_SIZE = 1\nGRADIENT_ACCUMULATION_STEPS = BATCH_SIZE // MICRO_BATCH_SIZE\nLEARNING_RATE = 3e-4\nTRAIN_STEPS = 100\nOUTPUT_DIR = \"/kaggle/working/tmp\"\n\ntraining_arguments = transformers.TrainingArguments(\n            per_device_train_batch_size=MICRO_BATCH_SIZE,\n            gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n#             warmup_steps=200,\n            max_steps=TRAIN_STEPS,\n            learning_rate=LEARNING_RATE,\n            fp16=True,\n            logging_steps=10,\n            optim=\"adamw_torch\",\n            evaluation_strategy=\"steps\",\n            save_strategy=\"steps\",\n            eval_steps=10,\n            save_steps=10,\n            output_dir=OUTPUT_DIR,\n            save_total_limit=10,\n            load_best_model_at_end=True,\n            report_to=None,\n            overwrite_output_dir=True, # Overwrite the content of the output dir\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T19:33:22.637251Z","iopub.execute_input":"2024-10-04T19:33:22.637637Z","iopub.status.idle":"2024-10-04T19:33:22.647400Z","shell.execute_reply.started":"2024-10-04T19:33:22.637605Z","shell.execute_reply":"2024-10-04T19:33:22.646470Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}]},{"cell_type":"code","source":"data_collator = transformers.DataCollatorForSeq2Seq(\n    tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T19:33:27.247678Z","iopub.execute_input":"2024-10-04T19:33:27.248044Z","iopub.status.idle":"2024-10-04T19:33:27.252800Z","shell.execute_reply.started":"2024-10-04T19:33:27.248014Z","shell.execute_reply":"2024-10-04T19:33:27.251804Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"!export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128","metadata":{"execution":{"iopub.status.busy":"2024-10-04T19:24:26.967793Z","iopub.execute_input":"2024-10-04T19:24:26.968192Z","iopub.status.idle":"2024-10-04T19:24:28.650929Z","shell.execute_reply.started":"2024-10-04T19:24:26.968159Z","shell.execute_reply":"2024-10-04T19:24:28.649563Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T19:24:30.148672Z","iopub.execute_input":"2024-10-04T19:24:30.149212Z","iopub.status.idle":"2024-10-04T19:24:30.155002Z","shell.execute_reply.started":"2024-10-04T19:24:30.149170Z","shell.execute_reply":"2024-10-04T19:24:30.154099Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Настройка тренера и передача модели в него\ntrainer = transformers.Trainer(\n    model=model,  # Модель для тренировки\n    train_dataset=train_data,  # Тренировочный датасет\n    eval_dataset=val_data,  # Валидационный датасет\n    args=training_arguments,  # Аргументы для тренировки\n    data_collator=data_collator  # Коллатор данных\n)\n\n# Запуск тренировки\ntrainer.train()\n\n# Сохранение обученной модели\nmodel.save_pretrained(OUTPUT_DIR)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T19:33:52.331388Z","iopub.execute_input":"2024-10-04T19:33:52.331769Z","iopub.status.idle":"2024-10-04T19:43:15.908531Z","shell.execute_reply.started":"2024-10-04T19:33:52.331740Z","shell.execute_reply":"2024-10-04T19:43:15.907679Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [100/100 09:16, Epoch 36/50]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>11.979400</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>8.297400</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>5.052200</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>18.143000</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>18.915000</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>15.772500</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>9.750200</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>15.809000</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>12.240600</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>16.319600</td>\n      <td>nan</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-10-04T19:18:30.002160Z","iopub.execute_input":"2024-10-04T19:18:30.003200Z","iopub.status.idle":"2024-10-04T19:18:30.007508Z","shell.execute_reply.started":"2024-10-04T19:18:30.003164Z","shell.execute_reply":"2024-10-04T19:18:30.006510Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"SYSTEM_PROMPT = \"Ты извлекаешь термины и определения из текста\"\nSYSTEM_TOKEN = 1788\nUSER_TOKEN = 1404\nBOT_TOKEN = 9225\nLINEBREAK_TOKEN = 13\n\ntop_k=40\ntop_p=0.5\ntemperature=0.01\nrepeat_penalty=1.1\n\n\nROLE_TOKENS = {\n    \"user\": USER_TOKEN,\n    \"bot\": BOT_TOKEN,\n    \"system\": SYSTEM_TOKEN\n}\n\n\ndef get_message_tokens(model, role, content):\n    message_tokens = model.tokenize(content.encode(\"utf-8\"))\n    message_tokens.insert(1, ROLE_TOKENS[role])\n    message_tokens.insert(2, LINEBREAK_TOKEN)\n    message_tokens.append(model.token_eos())\n    return message_tokens\n\n\ndef get_system_tokens(model):\n    system_message = {\n        \"role\": \"system\",\n        \"content\": SYSTEM_PROMPT\n    }\n    return get_message_tokens(model, **system_message)\n\ndef chat_saiga(message, model):\n    system_tokens = get_system_tokens(model)\n    tokens = system_tokens\n    # model.eval(tokens)\n    \n    message_tokens = get_message_tokens(model=model, role=\"user\", content=message)\n    role_tokens = [model.token_bos(), BOT_TOKEN, LINEBREAK_TOKEN]\n    tokens += message_tokens + role_tokens\n    # print(tokens)\n    # detokenize = model.detokenize(tokens)\n    # print(model.tokenize(full_prompt))\n    generator = model.generate(\n        tokens,\n        top_k = top_k,\n        top_p = top_p,\n        temp = temperature,\n        repeat_penalty = repeat_penalty,\n        reset = True\n    )\n    # print(len([token for token in generator]))\n    \n    result_list = []\n    \n    for token in generator:\n        token_str = model.detokenize([token]).decode(\"utf-8\", errors=\"ignore\")\n        tokens.append(token)\n        if token == model.token_eos():\n            break\n        print(token_str, end=\"\", flush=True)\n        result_list.append(token_str)\n    return ''.join(result_list)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T16:22:50.558441Z","iopub.execute_input":"2024-10-04T16:22:50.559181Z","iopub.status.idle":"2024-10-04T16:22:50.569650Z","shell.execute_reply.started":"2024-10-04T16:22:50.559148Z","shell.execute_reply":"2024-10-04T16:22:50.568717Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## Проверяем модель на адекватность","metadata":{}},{"cell_type":"code","source":"CUTOFF_LEN = 3584\n\ndef generate_prompt(data_point):\n    promt = f\"\"\"<s>system\n{data_point['system']}</s><s>user\n{data_point['user']}</s><s>bot\n{data_point['bot']}</s>\"\"\"\n    return promt\n \n    \ndef tokenize (prompt, add_eos_token=True):\n    result = tokenizer(\n        prompt,\n        truncation=True,\n        max_length=CUTOFF_LEN,\n        padding=False,\n        return_tensors=None,\n    )\n    if (\n        result[\"input_ids\"][-1] != tokenizer.eos_token_id and len(result[\"input_ids\"]) < CUTOFF_LEN\n        and add_eos_token\n    ):\n        \n        result[\"input_ids\"].append(tokenizer.eos_token_id)\n        result[\"attention_mask\"].append(1)\n        \n        \n    \n    result[\"labels\"] = result[\"input_ids\"].copy()\n\n    return result\n \ndef generate_and_tokenize_prompt(data_point):\n    full_prompt = generate_prompt(data_point)\n    tokenized_full_prompt = tokenize(full_prompt)\n    return tokenized_full_prompt","metadata":{"execution":{"iopub.status.busy":"2024-10-04T19:29:00.603919Z","iopub.execute_input":"2024-10-04T19:29:00.604801Z","iopub.status.idle":"2024-10-04T19:29:00.612215Z","shell.execute_reply.started":"2024-10-04T19:29:00.604749Z","shell.execute_reply":"2024-10-04T19:29:00.611368Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"DEFAULT_MESSAGE_TEMPLATE = \"<s>{role}\\n{content}</s>\"\nDEFAULT_RESPONSE_TEMPLATE = \"<s>bot\\n\"\nDEFAULT_SYSTEM_PROMPT = \"Ты отвечаешь на вопрос пользователя\"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nclass Conversation:\n    def __init__(\n        self,\n        message_template = DEFAULT_MESSAGE_TEMPLATE,\n        system_prompt = DEFAULT_SYSTEM_PROMPT,\n        response_template = DEFAULT_RESPONSE_TEMPLATE\n    ):\n        self.message_template = message_template\n        self.response_template = response_template\n        self.messages = [{\n            \"role\": \"system\",\n            \"content\": system_prompt\n        }]\n\n    def add_user_message(self, message):\n        self.messages.append({\n            \"role\": \"user\",\n            \"content\": message\n        })\n\n    def add_bot_message(self, message):\n        self.messages.append({\n            \"role\": \"bot\",\n            \"content\": message\n        })\n\n    def get_prompt(self, tokenizer):\n        final_text = \"\"\n        for message in self.messages:\n            message_text = self.message_template.format(**message)\n            final_text += message_text\n        final_text += DEFAULT_RESPONSE_TEMPLATE\n        return final_text.strip()\n\n\n\ndef generate(model, tokenizer, prompt, generation_config):\n    data = tokenizer(prompt,\n                     return_tensors=\"pt\",\n                     add_special_tokens=False,\n#                      padding=True,\n#                     truncation=True\n                    )\n    data = {k: v.to(device) for k, v in data.items()}\n    \n    output_ids = model.generate(\n        **data,\n        generation_config = generation_config,\n#         remove_invalid_values = True\n    )[0]\n    output_ids = output_ids[len(data[\"input_ids\"][0]):]\n    output = tokenizer.decode(output_ids, skip_special_tokens=True)\n    return output.strip()","metadata":{"execution":{"iopub.status.busy":"2024-10-04T20:30:40.293110Z","iopub.execute_input":"2024-10-04T20:30:40.293877Z","iopub.status.idle":"2024-10-04T20:30:40.304658Z","shell.execute_reply.started":"2024-10-04T20:30:40.293845Z","shell.execute_reply":"2024-10-04T20:30:40.303722Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"%%time\ndef get_message(inputs):\n    result = []\n    for inp in inputs:\n        conversation = Conversation()\n        conversation.add_user_message(inp)\n        prompt = conversation.get_prompt(tokenizer)\n        print(prompt)\n        output = generate(model, tokenizer, prompt, generation_config)\n        result.append(output)\n    return result","metadata":{"execution":{"iopub.status.busy":"2024-10-04T20:30:44.590733Z","iopub.execute_input":"2024-10-04T20:30:44.591443Z","iopub.status.idle":"2024-10-04T20:30:44.597931Z","shell.execute_reply.started":"2024-10-04T20:30:44.591408Z","shell.execute_reply":"2024-10-04T20:30:44.596889Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"CPU times: user 6 µs, sys: 2 µs, total: 8 µs\nWall time: 10.7 µs\n","output_type":"stream"}]},{"cell_type":"code","source":"p = \"\"\"\nИзвлеки из данного текста все определения и термины.\nВывод должен быть в виде списка словарей с ключами term и definition\n\nЛинейная модель — модель, отображающая состояние или функционирование системы таким образом, что все взаимозависимости в ней принимаются линейными (см. Линейная зависимость, Линейность в экономике). Соответственно, она может формулироваться в виде одного линейного уравнения или системы линейных уравнений.\nЛинейное пространство это математическая структура, представляющая собой набор элементов, называемых векторами, а яблоко это фрукт\n\"\"\"\nget_message([p])","metadata":{"execution":{"iopub.status.busy":"2024-10-04T20:24:15.166532Z","iopub.execute_input":"2024-10-04T20:24:15.166898Z","iopub.status.idle":"2024-10-04T20:25:41.946379Z","shell.execute_reply.started":"2024-10-04T20:24:15.166868Z","shell.execute_reply":"2024-10-04T20:25:41.945402Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"<s>system\nТы извлекаешь термины и определения из текста</s><s>user\n\nИзвлеки из данного текста все определения и термины.\nВывод должен быть в виде списка словарей с ключами term и definition\n\nЛинейная модель — модель, отображающая состояние или функционирование системы таким образом, что все взаимозависимости в ней принимаются линейными (см. Линейная зависимость, Линейность в экономике). Соответственно, она может формулироваться в виде одного линейного уравнения или системы линейных уравнений.\nЛинейное пространство это математическая структура, представляющая собой набор элементов, называемых векторами, а яблоко это фрукт\n</s><s>bot\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"['term: Линейная модель\\ndefinition: Модель, отображающая состояние или функционировку системы таким образом, что все взаимодействия между ее компонентами принимают линейные характер (см. Линейный анализ, Линейно-преобразованное пространство), соответственно можно выразить её одним линейным уравнением или системой линейных уравнений. \\n\\nterm: Линейное пространство\\ndefinition: Математическое пространство, которое является подпространством стандартного Euclidean space R^n для некоего n >= 1 и обладает свойствами линейности относительно операции сложения векторов над этим пространством. Этот тип пространств широко используется в различных дисциплинах, включая алгебру, теорию чисел, геометрию, топологию и другие. Они также играют важную роль в теории матриц и других объектах, связанных с линейной алгебре.\\n\\nterm: Яблоко\\ndefinition: Фрукты семейства Rosaceae, которые имеют мягкий плод без косточек, который обычно съедобен. Включает более чем тысячи видов, распространенных по всей Северной Америке, Европе и Азии. Некоторые из наиболее известных представителей этого рода включают грушу, черешню, брусницу, черники и калину. Кроме того, некоторые ягоды, такие как персиковые деревья и кустовое дерево, относятся к этой группе растений.']"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}