[
    {
        "question": "Дай определение надрегулярного множества в теории формальных языков. Определи множество регулярных языков",
        "answer": "____\nПусть задан алфавит Σ={c1,c2,…,ck}.\nМножество R\n будем называть надрегулярным множеством над алфавитом Σ, если:\n\nR0⊂R, где R0={∅,{ε},{c1},{c2},…,{ck}},\nL1,L2∈R⇒L1∪L2∈R,L1L2∈R,L∗1∈R.\nТогда множеством регулярных языков REG′\n над алфавитом Σ={c1,c2,…,ck}\n называется пересечение всех надрегулярных множеств над этим алфавитом."
    },
    {
        "question": "как проверить пару детерминированных конечных автоматов на эквивалентность с помощью поиска в ширину?",
        "answer": "____\nДва автомата можно также проверить на эквивалентность, используя обход в ширину. Будем синхронно обходить два автомата, начиная со стартовых состояний, в поисках такой строки, которая различает два состояния этих автоматов. То есть она будет допускаться одним автоматом, но не будет принадлежать языку другого.\n\nПоскольку эквивалентные автоматы допускают один и тот же язык, при переходе по одним и тем же символам в обоих автоматах, слово должно приниматься обоими автоматами одновременно. То есть вершины, в которые мы перешли, должны быть либо одновременно терминальными, либо одновременно нетерминальными, что и проверяет приведённый алгоритм.\n\nПсевдокод\n// aut[i][c]\n — номер состояния, в которое есть переход из состояния i\n по символу c\n\nboolean bfsEquivalenceCheck\n(aut1\n : int[][], aut2\n : int[][]):\n    Q.push(⟨s1,s2⟩)\n // Q\n — очередь из пар состояний\n    while Q≠∅\n \n        u,v←Q.pop()\n\n        if isTerminal1[u]≠isTerminal2[v]\n\n            return false\n        used[u][v]←\n true\n        for c∈Σ\n\n            if not used[aut1[u][c]][aut2[v][c]]\n\n                Q.push(⟨aut1[u][c],aut2[v][c]⟩)\n\n    return true\nКорректность алгоритма следует из строго доказательства того факта, что если два состояния u\n и v\n различаются какой-то строкой, то они различаются строкой длины O(n).\n\nИнтуитивное понимание алгоритма такое: пусть по строке w\n мы пришли в состояния ⟨u,v⟩, и пусть они оба нетерминальные. После этого совершим переход по символу c\n в состояния ⟨u′,v′⟩.\n\nТогда если isTerminal1[u′]≠isTerminal2[v′], то строка wc\n различает эти два состояния. А значит автоматы не эквивалентны."
    },
    {
        "question": "Какими свойствами обладают КС-языки относительно операций объединения, конкатенации, замыкания Клини, прямого гомоморфизма?",
        "answer": "____\nОбъединение\nL1∪L2\n  является КС-языком.\nДоказательство:\nПостроим КС-грамматику для языка L1∪L2. Для этого рассмотрим соответствующие КС-грамматики для языков L1\n и L2. Пусть стартовые символы в них имеют имена S\n и T\n соответственно. Тогда стартовый символ для L1∪L2\n обозначим за S′\n и добавим правило S′→S∣T.\n\nПокажем, что S′⇒∗w⟺S⇒∗w∨T⇒∗w.\n\n⇒\n\nПоскольку S⇒∗w\n и есть правило S′→S\n, то, по определению ⇒∗\n получаем, что S′⇒∗w. Аналогично и для T.\n⇐\n\nПусть S′⇒∗w. Поскольку S′→S∣T\n — единственные правила, в которых нетерминал S′\n присутствует в правой части, то это означает, что либо S′⇒S⇒∗w, либо S′⇒T⇒∗w.\n\nКонкатенация  \nL1L2\n — КС-язык.\nДоказательство\nНужно использовать идею прошлого доказательства и построить КС-грамматику для L1L2 с правилом S′→ST, где S\n и T\n — стартовые символы языков L1\n и L2\n соответственно.\n \nL∗=⋃i=0∞Li\n  — КС-язык.\n\nГомоморфизм\nКС-языки замкнуты относительно прямого гомоморфизма.\n\nОбратный гомоморфизм\nКС-языки замкнуты относительно обратного гомоморфизма.\n\nПересечение\nЕсли L1=aibicj,L2=aibjcj\n, то L1∩L2\n не является КС-языком.\n \nРазворот\nL^R={w^R∣w∈L}\nконтекстно-свободен."
    },
    {
        "question": "докажи, что язык алфавитной префиксной грамматики регулярен",
        "answer": "____\nОпределение APG\nДана SRS S с правилами переписывания двух видов:\nai → b1 . . . bn ai → ε\nРазрешим применять правила только к первым буквам\nслова. Пусть дана пара ⟨S, w0⟩, где w0 — слово в алфавите\nΣ. Эта пара определяет алфавитную префиксную\nграмматику.\nУтверждение\nЯзык L⟨S, w0⟩ регулярен.\n2 / 24\n▲\nАлфавитные префиксные грамматики\nУтверждение\nЯзык L⟨S, w0⟩ регулярен.\nСкажем, что a ↠ ε (a коллапсирует), если либо a → ε ∈ S, либо\n∃b1, . . . , bn(∀bi(bi ↠ ε) & a → b1 . . . bn ∈ S).\nПо APG ⟨S, s1 . . . sn⟩ породим праволинейную грамматику G. Каждому\nсимволу алфавита ai сопоставим Ai — нетерминал G.\n1 Пусть a → b1 . . . bn и ∃bi(¬(bi ↠ ε) & ∀j(j < i ⇒ bj ↠ ε)).\nТогда добавим в G правила A → B1b2 . . . bn, A → B2b3 . . . bn,. . . ,\nA → Bibi+1 . . . bn, A → a.\n2 Если такого bi нет, добавляем в G все правила вида\nA → B1b2 . . . bn, . . . , A → Bn−1bn, A → Bn, A → a.\n3 Вводим стартовый нетерминал S и для него добавляем развёртку в\nисходное слово s1 . . . sm по правилам выше.\n4 Если все si коллапсируют, тогда добавляем в G правило S → ε.\n2 / 24\n▲\nАлфавитные префиксные грамматики\nСкажем, что a ↠ ε (a коллапсирует), если либо a → ε ∈ S, либо\n∃b1, . . . , bn(∀bi(bi ↠ ε) & a → b1 . . . bn ∈ S).\nПо APG ⟨S, s1 . . . sn⟩ породим праволинейную грамматику G. Каждому\nсимволу алфавита ai сопоставим Ai — нетерминал G.\n1 Пусть a → b1 . . . bn и ∃bi(¬(bi ↠ ε) & ∀j(j < i ⇒ bj ↠ ε)).\nТогда добавим в G правила A → B1b2 . . . bn, A → B2b3 . . . bn,. . . ,\nA → Bibi+1 . . . bn, A → a.\n2 Если такого bi нет, добавляем в G все правила вида\nA → B1b2 . . . bn, . . . , A → Bn−1bn, A → Bn, A → a.\n3 Вводим стартовый нетерминал S и для него добавляем развёртку в\nисходное слово s1 . . . sm по правилам выше.\n4 Если все si коллапсируют, тогда добавляем в G правило S → ε.\nОстается сделать развертку правил вида A → Bn, либо перейти от G к\nНКА с ε-переходами.\n2 / 24\n▲"
    },
    {
        "question": "напиши лемму Ардена",
        "answer": "____\nПусть X = (pX) | q, где X — неизвестное RE, а p, q —\nизвестные, причём ε /∈ L (p). Тогда X = (p)\n∗q.\nТо есть p\n∗q — наименьшая (но не единственная) неподвижная\nточка выражения px | q по отношению ⩽, и единственная, если\nε /∈ L (p)."
    },
    {
        "question": "Сформулируй теорему о замкнутости регулярных языыков",
        "answer": "____\nПусть L1,L2\n — регулярные языки над одним алфавитом Σ. Тогда следующие языки также являются регулярными:\n Языки, полученные путём применения следующих теоретико-множественных операций:\n L1∪L2,\n L1¯¯¯¯¯¯,\n L1∩L2,\n L1∖L2;\n L∗1;\n L1L2; \n L1←;"
    },
    {
        "question": "Сформулируй теоремы о построении LL(k) грамматики без пустых правил",
        "answer": "____\nТеорема 1 \nДля всякой LL(k)-\nграмматики существует и может быть эффективно построена LL(k + 1)-грамматика\nбез пустых правил, задающая тот же язык.\n\nТеорема 2 \nДля всякой LL(k)-грамматики без пустых правил можно построить LL(k)-грамматику в н.в.Грейбах, задающую тот же язык."
    },
    {
        "question": "Сформулируй лемму Розенкранца и Стирнса для обыкновенной грамматики",
        "answer": "____\nЛемма 1 (Розенкранц и Стирнс [1970]). Для всякой обыкновенной грамматики G =\n(Σ, N, R, S), существует другая грамматика G0 = (Σ, N ∪ N0, R0, S0), где N0 = { A0| A ∈\nN }, удовлетворяющая следующим условиям.\n1. Всякий нетерминальный символ A ∈ N задаёт в G0 тот же язык, что и в G.\n2. Всякий нетерминальный символ A0 ∈ N в G0\nзадаёт тот же язык, что и в G, с\nисключённой пустой строкой: LG0(A0) = LG(A0) \\ {ε}. В частности, L(G0) = L(G) \\{ε}.\n3. Никакое правило из R0 не начинается с нетерминального символа из N.\n4. Если G — LL(k), то и G0 — тоже LL(k)."
    },
    {
        "question": "Сформулируй лемму Розенкранца и Стирнса для LL(k)-грамматики",
        "answer": "____\nЛемма 2 (Розенкранц и Стирнс [1970]). Пусть G = (Σ, N, R, S) — LL(k)-грамматика,\nне содержащая правил вида A → Bγ, где ε ∈ LG(B). Пусть обнуляемые нетерминальные\nсимволы обозначаются через N0 = { A | A ∈ N, ε ∈ LG(A) }, и пусть N1 = { A | A ∈ N, ε /∈\nLG(A) } — все остальные. Тогда существует LL(k + 1)-грамматика G0 = (Σ, N0, R0, S0),где N0 — конечное множество нетерминальных символов вида [Xθ], где X ∈ Σ ∪ N1 и\nθ ∈ N∗0, и LG0([Xθ]) = LG(Xθ) для всякого [Xθ] ∈ N0\n[Xθ] ∈ N0.\nПри этом множество N0 не содержит ни одного элемента вида [XθAθ0Aθ00], который\nсодержал бы повторяющиеся вхождения одного и того же нетерминального символа."
    },
    {
        "question": "Напиши теорему о непересекающемся объединении LL(k)-языков",
        "answer": "____\nТеорема (О непересекающемся объединении LL(k)-языков: Розенкранц и Стирнс [1970]).\nПусть L1, . . . , Ln ⊆ Σ\n∗ — попарно непересекающиеся LL(k)-языки, и пусть их объединение\nL1 ∪ . . . ∪ Ln регулярно. Тогда все языки L1, . . . , Ln должны быть регулярны."
    },
    {
        "question": "Расскажи про свойства LL-грамматик",
        "answer": "____\nГрамматику, которая была бы LL(k), но не LL(k − 1), построить легко: например, S →\na\nk\n| a\nk−1 — такая грамматика. Но в данном примере есть очевидная LL(1)-грамматика для\nтого же языка: S → a\nk−1A, A → a | ε. Растёт ли класс языков с увеличением k? Да.\nЛемма 1. Пусть G = (Σ, N, R, S) — LL(k)-грамматика без пустых правил, и пусть вычисление LL(k)-анализатора на некоторой строке w = xyz после чтения x приводит в\nконфигурацию (yz, Y γ), и затем, после чтения y, — в конфигурацию (z, γ). Тогда для всякой строки z\n0, совпадающей z в первых k − 1 символах, вычисление на xyz0 приходит в\nконфигурацию (z\n0, γ).\nНабросок доказательства. Разбирая y в виде Y , анализатор при каждом выборе правила\nвидит не менее одного последнего символа y. Поэтому различия между z и z\n0 при этом\nвыборе окажутся за горизонтом, и, стало быть, анализатор одинаково прочитает y в обоих\nслучаях.\nТеорема 1 (Курки-Суонио [1969]; Розенкранц и Стинрс [1970]). Для всякого k > 1, существует язык Lk, задаваемый LL(k)-грамматикой, но не задаваемый никакой LL(k)-\nграмматикой без пустых правил — и, стало быть, никакой LL(k − 1)-грамматикой.\nДоказательство. Язык Lk определяется как Lk =S\nn>1\na^n{b^kd, b, c}^n, и он описывается\nследующей грамматикой.\nS → aCA\nC → aCA | ε\nA → bB | c\nB → b\nk−1\nd | ε\nЧтобы убедиться, что эта грамматика — LL(k), нужно проверить, что анализатор может\nвыбрать правило для B. Действительно, правило B → ε выбирается для всех просматриваемых строк Firstk(LG(A)\n+), каковые все состоят целиком из символов b и c: строка b\nk−1d\nне относится к числу этих строк.\nОтрицательный результат получается методом подменяемой строки впереди. Если Lk\nзадаётся LL(k)-грамматикой без пустых правил, то, по теореме из прошлой лекции, есть\nLL(k)-грамматика G = (Σ, N, R, S) в нормальном виде Грейбах, задающая язык L(G) = Lk.\nПусть αn — содержимое стека соответствующего LL(k)-анализатора на входе a\nn+k−1\n. . .,\nпосле прочтения символов u = a\nn\n.\nУтверждение. αm 6= αn для всех m 6= n.\nУтверждение. Существует число n > 0, для которого |αn| > 2k − 1"
    },
    {
        "question": "Что такое локальные автоматы",
        "answer": "____\nОпределение:\nАвтомат A\n называется локальным (англ. local automaton, Glushkov automaton), если для любого c\n из Σ\n множество {δ(s,c)∣s∈S}\n содержит не более одного элемента.\n\n\nОпределение:\nЛокальный автомат A\n называется стандартным локальным автоматом (англ. standard local automation), если в нем нет перехода в начальное состояние.\n\nТаким образом, автомат является локальным, если для каждого c\n из Σ\n нет переходов, отмеченных c, или если все они ведут в одно состояние.\n\nПокажем, что граф Майхилла может быть преобразован в стандартный локальный автомат таким образом, что распознаваемый им язык не изменится.\n\nТеорема:\nЯзык распознается графом Майхилла тогда и только тогда, когда он распознается стандартным локальным автоматом, стартовое состояние которого не является терминальным."
    },
    {
        "question": "Следствие теоремы Турчина",
        "answer": "____\nПусть G - алфавитная префиксная грамматик, в которой N правил с непустой правой частью, и максимальная длина правой части правила равна M. Тогда любая последовательность порождаемых ею слов\na_1...a_n\n...\nε\nдлиной не менее N^M*(n+1) содержит пару вида τ_1=Φ*Θ_0, τ_2=Φ*Ψ*Θ_0 такую, что |Φ|<=M и на отрезке [τ_1, τ_2] нет слов длины меньше |Θ_0|+1."
    },
    {
        "question": "Критерий синхронизации",
        "answer": "____\nDFA A синхронизирующийся <=> ∀q,q'∃w, q_x(q-w->q_x & q' -w->q_x)."
    },
    {
        "question": "Докажите, что множество автоматных грамматик образует булеву алгебру",
        "answer": "____\nКласс регулярных множеств образует булеву алгебру. Класс регулярных множеств замкнут\nотносительно реверса?\nΩ=<∨,∧,¬> - сигнатура булевой алгебры\nСвойства булевой алгебры:\n● A∧B=B∧A - коммутативность по умножению\n● A∧(B∧C)=(A∧B)∧C - ассоциативность по умножению\n● A∧(B∨C)=(A∧B) ∨(A∧C) - дистрибутивность\n● ¬¬A=A\n● A∨¬A=1\n● A∧¬A=0\n● A∧1=A\n● A∧0=A\n● A∨0=A\n● A∨1=1\nДоказательство:\nСвойства операций сложения и умножения следуют из Леммы о регулярных выражениях\nДополнение регулярного множества является регулярным ⇐ если множество регулярно, то оно\nраспознаётся автоматом. Если в автомате M изменить множество конечных состояний на Q\\F, то\nполучим автомат , который распознаёт дополнение к заданному языку."
    },
    {
        "question": "Сформулировать теорему Майхилла-Нероуда",
        "answer": "____\nЯзык L является VPL => множество сбалансированных слов(т.е. таких, каждый символ из Σ_с в которых имеет соответствующий символ из Σ_r) разбивается на конечное число классов эквивалентности по Майхиллу-Нероуду относительно L."
    },
    {
        "question": "Что такое конъюктивная грамматика?",
        "answer": "____\nКонъюнктивная грамматика G - грамматика, правила которой имеют вид A_i -> Φ_1 & ... & Φ_2 где A_i - нетерминал; Φ_j - строки в смешанном алфавите терминалов и нетерминалов."
    },
    {
        "question": "Что такое древесный автомат?",
        "answer": "____\nДревесный автомат задается входным алфавитом(сигнатурой конструкторов) Σ⊂{⟨f, n⟩} и конечным состоянием, а также правилами перехода: ⟨f, n⟩ ∈ Σ => (q_1,..., q_n, f)->q_s."
    },
    {
        "question": "Следствия теоремы Париха",
        "answer": "____\n1)Множества регулярных и КС-языков над однобуквенным алфавитом совпадают.\n2)Коммутативным образом КС-языка является регулярный язык."
    },
    {
        "question": "Пересечение КС-грамматики и регулярного языка",
        "answer": "____\nДаны КС-грамматика G и конечный автомат A. Можно построить КС-грамматику G' такую, что L(G')=L(G)∩L(A)."
    },
    {
        "question": "Что такое стековый автомат?",
        "answer": "____\nСтековый автомат A - кортеж ⟨Π, Σ, Q, δ, q_0, Z_0⟩, где:\nΠ - алфавит стека;\nΣ - алфавит языка;\nQ - множество состояний;\nδ - правила перехода вида ⟨q_i, t, P_i⟩ -> ⟨q_j, α⟩, где t ∈ Σ ∪ {ε}, α ∈ Π*\nq_0 - стартовое сотояние;\nZ_0 - дно стека."
    },
    {
        "question": "Доказать алгоритм Эрли",
        "answer": "____⟹\n\nДокажем индукцией по исполнению алгоритма.\nБаза индукции:\n[S′→⋅S,0]∈D0.\nИндукционный переход:\nПусть предположение верно для всех списков ситуаций с номерами меньше j. Разберемся, в результате применения какого правила ситуация [A→α⋅β,i] попала в Dj\n1. Включаем по правилу scan. Это произошло, если α=α′a, a=wj−1 и [A→α′⋅aβ,i]∈Dj−1.\nПо предположению индукции S′⇒∗w0…wi−1Aδ и α′⇒∗wi…wj−2, тогда в силу a=wj−1 получаем α=α′a⇒∗wi…wj−2wj−1=wi…wj−1. Таким образом условия: S′⇒∗w0…wi−1Aδ и α⇒∗wi…wj−1 выполняются.\n2. Включаем по правилу predict. По построению: α=ε и i=j, что автоматически влечет второй пункт утверждения.\nКроме того ∃i′≤i и ситуация [A′→α′⋅Aδ′,i′]∈Di, из чего по  предположению индукции следует S′⇒∗w0…wi′−1A′δ′′ и α′⇒∗wi′…wi−1.\nПолучаем, что S′⇒∗w0…wi′−1A′δ′′, значит S⇒∗w0…wi′−1α′Aδ′δ′′, следовательно S′⇒∗w0…wi′−1wi′…wi−1Aδ′δ′′, в итоге S′⇒∗w0…wi−1Aδ, что нам и требовалось.\n3. Включаем по правилу complete. По построению: α=α′A′ и ∃i′,δ:[A→α′⋅A′β,i]∈Di′∧[A′→η⋅,i′]∈Dj. Cледовательно α=α′A ⇒∗wi…wi′−1wi′…wj=wi…wj−1, что дает нам второй пункт утверждения, а так как первый пункт следует из индукционного предположения, все хорошо.\n\n⟸\n\nВ обратную сторону будем доказывать индукцией по суммарной длине вывода w0…wi−1Aδ  из S′ и wi…wj−1 из α. После чего применим индукцию по длине вывода wi…wj−1 из α. Рассмотрим три случая последнего символа α:\n1. α=α′a, тогда a=wj−1 и α′⇒∗wi…wj−2. По предположению индукции: [A→α′⋅aβ,i]∈Dj−1, а отсюда по правилу scan получаем [A→α′a⋅β,i]∈Dj.\n2. α=α′B, тогда ∃i′:α′⇒∗wi…wi′−1∧B′⇒∗wi′…wj−1.Тогда имеем [A→α′a⋅β,i]∈Dj. Также можно записать S′⇒∗w0…wi−1Aδ, как S′⇒∗w0…wi−1wi…wi′−1Bβδ, а также B→η∧η→wi′…wj−1.\nПрименяя индукцию по второму параметру получим [B→η⋅,i′]∈Dj, откуда по правилу complete получаем [A→α′B⋅β,i]∈Dj.\n\n3. α=ε, тогда i=j. Тогда либо i=0∧A=S∧δ=ε, что доказывает базу индукции, либо вывод можно записать в виде S′⇒∗w0…wi′−1wi′…wi−1Aδ′δ′′=w0…wi−1Aδ для некоторого правила (A′→wi′…wi−1Aδ′)∈P.\nОтсюда по предположению индукции [A′→⋅wi′…wi−1Aδ′,i′]∈Di′ , что после нескольких применений правила scan приводит к [A′→wi′…wi−1⋅Aδ′,i′]∈Di, после чего по правилу predict  получим [A→⋅β,i]∈Dj, что и требовалось."
    },
    {
        "question": "LL-подгонка",
        "answer": "____\n●Устранение левой рекурсии\n●Извлечение левого контекста:\nЕсли даны A->Φγ_1, A-> Φγ_2, тогда можно построить эквивалентные правила A -> ΦA', A'-> γ_1|γ_2."
    },
    {
        "question": "Рекурсивный нетерминал",
        "answer": "____\nРекурсивный нетерминал — это нетерминальный символ в грамматике, который можно вывести в строку, содержащую самого себя. То есть, в процессе развертывания правил грамматики нетерминал может привести к цепочке вывода, где он снова появляется.\nНапример, если нетерминал \\( A \\) имеет правило \\( A \\rightarrow \\alpha A \\beta \\) или через несколько шагов выводится в такое, то \\( A \\) является рекурсивным."
    },
    {
        "question": "Леворекурсивный нетерминал",
        "answer": "____\nЛеворекурсивный нетерминал — это нетерминал, у которого есть правило, где он стоит первым символом в правой части своего собственного правила, то есть \\( A \\rightarrow A \\alpha \\), где \\( \\alpha \\) — некоторая строка символов.\nЛеворекурсия может приводить к проблемам при нисходящем разборе (парсинге), так как может вызывать бесконечную рекурсию в рекурсивных парсерах."
    },
    {
        "question": "Праворекурсивный нетерминал",
        "answer": "____\nПраворекурсивный нетерминал — это нетерминал, у которого есть правило, где он стоит последним символом в правой части своего собственного правила, то есть \\( A \\rightarrow \\alpha A \\), где \\( \\alpha \\) — некоторая строка символов.\nПраворекурсия обычно не вызывает проблем при нисходящем разборе и может быть предпочтительнее для некоторых типов парсеров, хотя может влиять на эффективность при больших глубинах рекурсии."
    },
    {
        "question": "Рассмотрим следующую контекстно-свободную грамматику \\( G \\):\n\n1. \\( S \\rightarrow aSb \\)\n2. \\( S \\rightarrow SS \\)\n3. \\( S \\rightarrow \\varepsilon \\)\nДокажите, что язык \\( L(G) \\), порождаемый грамматикой \\( G \\), непуст и опишите этот язык.",
        "answer": "____\nГрамматика \\( G \\) непустая, поскольку содержит правило \\( S \\rightarrow \\varepsilon \\), которое позволяет вывести пустую строку \\( \\varepsilon \\). Это означает, что \\( \\varepsilon \\in L(G) \\), и, следовательно, язык \\( L(G) \\) непуст.\n\nОпишем язык \\( L(G) \\), порождаемый грамматикой:\n\n1. Правило \\( S \\rightarrow aSb \\): Оно порождает строки, которые начинаются с символа \\( a \\), заканчиваются символом \\( b \\), а между ними может быть рекурсивно вставлена такая же структура. Это создает баланс между количеством \\( a \\) и \\( b \\), где каждому \\( a \\) слева соответствует \\( b \\) справа.\n\n2. Правило \\( S \\rightarrow SS \\): Это правило позволяет конкатенировать две любые строки, порожденные из \\( S \\). Таким образом, мы можем комбинировать несколько структур, порожденных первым правилом, или даже другие конкатенации.\n\n3. Правило \\( S \\rightarrow \\varepsilon \\): Позволяет завершить вывод и порождает пустую строку.\n\nОписание языка \\( L(G) \\):\n\nЯзык \\( L(G) \\) состоит из всех строк, содержащих равное количество символов \\( a \\) и \\( b \\), где символы \\( a \\) и \\( b \\) могут быть расположены таким образом, что каждая позиция символа \\( a \\) слева соответствует символу \\( b \\) справа, но также допускаются конкатенации таких структур.\n\nТо есть, \\( L(G) = \\{ w \\in \\{a, b\\}^* \\mid |w|_a = |w|_b \\} \\)."
    },
    {
        "question": "Рассмотрим следующую контекстно-свободную грамматику \\( G \\):\n\n1. \\( S \\rightarrow aSb \\)\n2. \\( S \\rightarrow SS \\)\n3. \\( S \\rightarrow \\varepsilon \\)\nПостройте недетерминированный магазинный автомат (НМПА), эквивалентный грамматике \\( G \\).",
        "answer": "____\nДля построения НМПА, распознающего язык \\( L(G) \\), мы можем воспользоваться следующим подходом:\n\nАлфавит ввода: \\( \\{a, b\\} \\)\n\nАлфавит стека: \\( \\{A\\} \\) (символ для отслеживания количества \\( a \\))\n\nНабор состояний: \\( \\{q_0\\} \\) (начальное и единственное состояние)\n\nФункции переходов:\n\n1. Обработка символа \\( a \\):\n\n   При чтении символа \\( a \\), НМПА кладет символ \\( A \\) в стек.\n\n   \\( \\delta(q_0, a, Z) = \\{ (q_0, AZ) \\} \\)\n\n   \\( \\delta(q_0, a, A) = \\{ (q_0, AA) \\} \\)\n\n2. Обработка символа \\( b \\):\n\n   При чтении символа \\( b \\), НМПА снимает символ \\( A \\) с вершины стека, если он там есть.\n\n   \\( \\delta(q_0, b, A) = \\{ (q_0, \\varepsilon) \\} \\)\n\n3. Обработка пустого символа (для принятия пустой строки):\n\n   \\( \\delta(q_0, \\varepsilon, Z) = \\{ (q_0, Z) \\} \\)\n\nОписание работы НМПА:\n\n- НМПА начинает в состоянии \\( q_0 \\) со стеком, содержащим начальный символ \\( Z \\).\n\n- При чтении каждого символа \\( a \\) автомат кладет \\( A \\) в стек, увеличивая счетчик количества \\( a \\).\n\n- При чтении каждого символа \\( b \\) автомат снимает \\( A \\) с вершины стека, уменьшая счетчик.\n\n- Если после обработки всей входной строки стек возвращается к начальному символу \\( Z \\) (т.е. стек пуст в отношении символов \\( A \\)), автомат принимает строку.\n\n- НМПА принимает строку, если количество символов \\( a \\) равно количеству символов \\( b \\).\n\nСоответствие грамматике \\( G \\):\n\n- Правило \\( S \\rightarrow aSb \\) соответствует увеличению стека на \\( A \\) при чтении \\( a \\) и последующему уменьшению при чтении \\( b \\).\n\n- Правило \\( S \\rightarrow SS \\) соответствует недетерминированности НМПА, позволяющей ему разделять строку на подстроки, обрабатываемые независимо.\n\n- Правило \\( S \\rightarrow \\varepsilon \\) соответствует возможности НМПА принять пустую строку без изменения стека."
    },
    {
        "question": "Рассмотрим следующую контекстно-свободную грамматику \\( G \\):\n\n1. \\( S \\rightarrow aSb \\)\n2. \\( S \\rightarrow SS \\)\n3. \\( S \\rightarrow \\varepsilon \\)\nОбъясните, почему невозможно построить детерминированный магазинный автомат, распознающий язык \\( L(G) \\).",
        "answer": "____\nЯзык \\( L(G) \\) состоит из всех строк над алфавитом \\( \\{a, b\\} \\), в которых количество символов \\( a \\) равно количеству символов \\( b \\). Этот язык не является детерминированным контекстно-свободным.\n\nПричины невозможности построения детерминированного МПА:\n\n1. Отсутствие возможности предсказания:\n\n   Детерминированный МПА должен на каждом шаге однозначно определять действие (переход и операция со стеком) на основе текущего состояния, символа входа и символа на вершине стека.\n\n   В языке \\( L(G) \\) символы \\( a \\) и \\( b \\) могут появляться в любом порядке, при этом решение, когда положить символ в стек или когда извлечь его, не может быть принято однозначно на основе текущей информации.\n\n2. Недетерминированность необходима для балансировки:\n\n   Чтобы определить, соответствует ли данная строка условию \\( |w|_a = |w|_b \\), автомат должен \"заглядывать\" вперед или помнить неопределенное количество информации о прочитанных символах. Это требует недетерминированных выборов.\n\n3. Пример невозможности однозначного перехода:\n\n   Рассмотрим ситуацию, когда автомат прочитал несколько символов \\( a \\) и \\( b \\) в произвольном порядке. При встрече следующего символа автомат не может однозначно решить, следует ли добавить символ в стек или извлечь его, так как не известно, какие символы еще последуют.\n\nЗаключение:\n\nНедетерминированность необходима для распознавания языка \\( L(G) \\), поскольку автомат должен рассматривать все возможные варианты распределения символов \\( a \\) и \\( b \\), обеспечивающих условие равенства их количества. Это невозможно реализовать в детерминированном МПА, где каждый шаг строго определен."
    },
    {
        "question": "Алгоритм избавления от левой рекурсии",
        "answer": "____\n\nШаги алгоритма устранения левой рекурсии:\n\n1. Идентификация левой рекурсии:\n   - Непосредственная левая рекурсия: Когда правило имеет вид A → Aα | β, где A — нетерминал, α — последовательность символов (непустая), а β — альтернатива, которая не начинается с A.\n   - Косвенная левая рекурсия: Когда последовательность правил приводит к ситуации, где A → Bα, а B может вывести A в качестве первого символа (т.е. B ⇒+ A).\n\n2. Устранение непосредственной левой рекурсии для каждого нетерминала:\n   Для каждого нетерминала A, имеющего правила вида:\n   \n\n   A → Aα₁ | Aα₂ | ... | Aαₙ | β₁ | β₂ | ... | βₘ\n   \n   где β₁, β₂, ..., βₘ — альтернативы, которые не начинаются с A.\n\n   - Создаем новый нетерминал A'.\n   - Переписываем правила следующим образом:\n     \n\n     A  → β₁A' | β₂A' | ... | βₘA'\n     A' → α₁A' | α₂A' | ... | αₙA' | ε\n     \n     Здесь ε обозначает пустую строку (эпсилон).\n\n3. Устранение косвенной левой рекурсии:\n   - Упорядочиваем нетерминалы в некотором порядке A₁, A₂, ..., An.\n   - Для каждого нетерминала Ai от i = 1 до n:\n     - Для каждого правила вида Ai → Ajγ, где j < i:\n       - Заменяем Aj на его правые части.\n     - После замены устраняем непосредственную левую рекурсию из правил для Ai, используя метод из шага 2."
    },
    {
        "question": "Различия между контекстно-свободной грамматикой и автоматной грамматикой",
        "answer": "____\nКлючевые различия между контекстно-свободными (КС) грамматиками и автоматными грамматиками\n\nКонтекстно-свободные грамматики (КС-грамматики):\n\nКонтекстно-свободные грамматики являются более мощным инструментом для описания языков по сравнению с регулярными (автоматными) грамматиками. Они используются для определения контекстно-свободных языков и занимают второй уровень в иерархии Хомского (типа 2).\n- Правила имеют вид: \\(A \\rightarrow \\alpha\\), где \\(A\\) — нетерминальный символ, а \\(\\alpha\\) — произвольная строка из терминальных и нетерминальных символов.\n\nАвтоматные грамматики (Регулярные грамматики):\n\nАвтоматные грамматики, также известные как регулярные грамматики, являются самым простым классом грамматик и соответствуют регулярным языкам. Они находятся на самом низком уровне иерархии Хомского (типа 3).\n- Правила имеют вид:\n    - Праволинейные грамматики: \\(A \\rightarrow aB\\) или \\(A \\rightarrow a\\)\n    - Леволинейные грамматики: \\(A \\rightarrow Ba\\) или \\(A \\rightarrow a\\)\n    - Где \\(A\\) и \\(B\\) — нетерминалы, \\(a\\) — терминальный символ.\n\n*Основные различия:\n\n1. **Выразительная мощность:\n   - КС-грамматики способны описывать более сложные языки с рекурсией и вложенностями.\n   - Регулярные грамматики ограничены описанием простых последовательностей без рекурсивных структур.\n\n2. Типы правил производства:\n   - В КС-грамматиках на левой стороне правила всегда один нетерминал, а правая сторона может быть любой строкой из терминалов и нетерминалов.\n   - В регулярных грамматиках правая часть правила ограничена одним терминалом, возможно с последующим нетерминалом (для праволинейных грамматик), или нетерминалом, предшествующим терминалу (для леволинейных грамматик).\n\n3. Соответствующие автоматы:\n   - КС-языки распознаются автоматами с магазинной памятью, которые имеют стек для учета вложенных структур.\n   - Регулярные языки распознаются конечными автоматами без дополнительной памяти.\n\n4.Замкнутость относительно операций:\n   - Регулярные языки замкнуты относительно объединения, конкатенации, замыкания Клини, пересечения и дополнения.\n   - КС-языки замкнуты относительно объединения, конкатенации и замыкания Клини, но не замкнуты относительно пересечения и дополнения."
    },
    {
        "question": "Что такое сильная и слабая бисимуляция?",
        "answer": "____\n\nСильная бисимуляция\nПусть есть два конечных автомата или системы с переходами, A и B, со множествами состояний S_A и S_B соответственно. Сильная бисимуляция — это отношение R⊆S_A×S_B, которое выполняется, если для любой пары состояний (s_A, s_B)∈R:\n1. Если в A из состояния s_A​ есть переход по метке α в состояние s_A'​, то в B из состояния s_B​ тоже должен быть переход по α в состояние s_B'​, и (s_A', s_B')∈R.\n2. Аналогично, если в B из состояния s_B​ есть переход по α, то в A из состояния s_A также должен быть переход по α, и эти состояния снова должны быть в отношении R.\n\nСлабая бисимуляция\n\nПусть снова есть два конечных автомата или системы с переходами, A и B, со множествами состояний S_A​ и S_B​. Слабая бисимуляция — это отношение R⊆S_A×S_B, где:\n1. Если в A из состояния s_A есть последовательность переходов, включая нулевое или более количество τ-переходов, по метке α в состояние s_A'​, то в B также должна быть последовательность переходов, включая нулевое или более количество τ-переходов, по метке α в состояние s_B', и (s_A', s_B')∈R.\n2. Аналогично, если в B из состояния s_B​ есть последовательность переходов по метке α в состояние s_B'​, то в A должна быть соответствующая последовательность переходов."
    },
    {
        "question": "Что такое поведенческая эквивалентность? В чем отличие от бисимуляции?",
        "answer": "____\n\nПоведенческая эквивалентность — это понятие, используемое в теории конечных автоматов и систем с переходами для описания того, что два состояния (или две системы) ведут себя одинаково с точки зрения наблюдателя. \nДва состояния считаются поведенчески эквивалентными, если при одинаковых входных данных они переходят в эквивалентные состояния и производят одинаковые выходы.\nПоведенческая эквивалентность — это более общее понятие, чем бисимуляция. В случае поведенческой эквивалентности важно только внешнее поведение, а не структура переходов в системе."
    },
    {
        "question": "Что такое обратная бисимуляция?",
        "answer": "____\n\nОбратная бисимуляция — это разновидность отношения бисимуляции, которая используется для сравнения поведения состояний в системах с переходами, таких как конечные автоматы. \nВ классической бисимуляции сравниваются шаги из одного состояния в другое (переходы), но в обратной бисимуляции мы смотрим на предыдущие шаги, то есть как состояния \"возвращаются\" к предыдущим состояниям через обратные переходы."
    },
    {
        "question": "Напиши доказательство теоремы Бржозовского?",
        "answer": "____\n\nУтверждение 1.\nАвтомат является детерминированным тогда и только тогда, когда левые языки его состояний попарно не пересекаются.\nУтверждение 2.\nЕсли A распознает язык L, то r(A) распознает r(L).\nУтверждение 3.\nЕсли левый язык состояния q в A — L_g(q), тогда его левый язык в r(A) — L_d(q). Аналогично для правого языка q.\nУтверждение 4.\nПравый язык состояния q′d(A) эквивалентен объединению правых языков состояний q автомата A, принадлежащих множеству q′.\nУтверждение 5.\nДетерминированный автомат минимален тогда и только тогда, когда правые языки его состояний различны и все состояния достижимы.\n\nПо построению автомат drdr(A) детерминированный. Согласно утверждению 2, он распознает язык L.\nПокажем, что все правые языки drdr(A) различны. Из утверждения 1, левые языки dr(A) попарно не пересекаются. Из утверждения 3, правые языки rdr(A) являются левыми языками dr(A). Таким образом, они попарно не пересекаются. Согласно утверждению 4, правый язык drdr(A) — объединение правых языков rdr(A). Поскольку правые языки rdr(A) попарно не пересекаются, все правые языки drdr(A) различны.\nТак как все правые языки drdr(A) различны, согласно утверждению 5 автомат drdr(A) минимальный."
    },
    {
        "question": "Опиши алгоритм Ахо-Корасика.",
        "answer": "____\n\nАлгоритм Ахо-Корасика\nОписание:\nАлгоритм Ахо-Корасика используется для поиска нескольких строк в тексте одновременно. \nОн строит автомат, который позволяет эффективно находить все вхождения заданных подстрок (шаблонов) в строке текста за время, пропорциональное длине текста и общему числу символов в шаблонах.\nЭтот алгоритм сочетает в себе элементы автоматного и префиксного дерева (Trie).\nОсновные этапы:\n1. Построение префиксного дерева (Trie): Сначала создается префиксное дерево для всех шаблонов. Каждый узел дерева представляет символ, а путь от корня до узла соответствует префиксу одного из шаблонов.\n2. Добавление переходов: На каждом уровне префиксного дерева добавляются переходы для символов, которые не соответствуют существующим путям, с использованием \"состояний неудачи\", чтобы указать, куда переходить в случае неудачи.\n3. Построение состояний неудачи: Каждому состоянию (узлу) присваивается состояние неудачи, указывающее, на какой узел следует переходить, если соответствующий символ не найден. Это позволяет обрабатывать текст более эффективно, избегая повторных проверок.\n4. Поиск: Текст обрабатывается одним проходом. При чтении каждого символа проверяются возможные переходы в автомате, и при нахождении конца шаблона фиксируется соответствующее вхождение."
    },
    {
        "question": "Опиши алгоритм Барроуза-Уилера.",
        "answer": "____\n\nАлгоритм, используемый для предварительной обработки данных перед сжатием, разработанный для улучшения эффективности последующего кодирования. \nПреобразование Барроуза — Уилера меняет порядок символов во входной строке таким образом, что повторяющиеся подстроки образуют на выходе идущие подряд последовательности одинаковых символов.\nОписание алгоритма\nПреобразование выполняется в три этапа:\n1. Составляется таблица всех циклических сдвигов входной строки.\n2. Производится лексикографическая (в алфавитном порядке) сортировка строк таблицы.\n3. В качестве выходной строки выбирается последний столбец таблицы преобразования и номер строки, совпадающей с исходной."
    },
    {
        "question": "Напишите лемму о разрастании для КС-грамматик.",
        "answer": "____\n\nПусть L — контекстно-свободный язык над алфавитом Σ, тогда существует такое n, что для любого слова ω∈L длины не меньше n найдутся слова u,v,x,y,z∈Σ∗, для которых верно: uvxyz=ω,vy≠ε,|vxy|⩽n и ∀k⩾0 uv_kxy_kz∈L."
    },
    {
        "question": "Опиши способы получения минимальных автоматов.",
        "answer": "____\n\nТаблица переходов\n\nЕсли заданы таблица переходов и эквивалентное разбиение Σ1..Σň автомата S, то таблица переходов Š может быть построена следующим образом:\n1. Заменить обозначение каждого состояния, имеющегося в таблице S на обозначение класса, которому данное состояние принадлежит.\n2. Из каждой группы строк с одинаковыми обозначениями в клетках основного столбца вычеркнуть все строки, кроме одной.\nПолученная при этом таблица является таблицей переходов Š.\n\nГраф переходов\n\nЕсли заданы граф переходов (диаграмма состояний) и эквивалентное разбиение Σ1..Σň автомата S, то граф переходов Š может быть построен следующим образом:\n1. Заменить обозначение каждого состояния, имеющегося в графе переходов S на обозначение класса, к которому относится данное состояние.\n2. Объединить все одинаково обозначенные состояния (рассматривая дуги графа как «гибкие связи») и представить объединенные состояния одним состоянием, имеющим общее обозначение.\n3. Из каждой группы дуг, имеющих общее исходное и общее конечное состояние вычеркнуть все, кроме одной.\nПолученный в результате граф будет графом Š.\n\nМатрица переходов\n\nЕсли заданы матрица переходов и эквивалентное разбиение Σ1..Σň автомата S, то матрица переходов Š может быть построена следующим образом:\n1. Провести симметрическую перестановку и симметрическое разбиение [S] так, чтобы строки (и столбцы) группировались соответственно классам эквивалентности S (эту же матрицу можно получить при матричном методе эквивалентного разбиения).\n2. Заменить все обозначения строк (и столбцов) каждой группы, представляющей класс эквивалентности, одним обозначением этого класса.\n3. Заменить каждую подматрицу в разбитой матрице одной клеткой, содержащей все пары вход-выход, которые имеются в любой строке этой подматрицы (все строки в любой такой подматрице содержат одно и то же множество пар вход-выход).\nПолученная в результате матрица является матрицей переходов Š."
    },
    {
        "question": "Напиши свойства минимального автомата.",
        "answer": "____\n\nЕсли Š является минимальной формой автомата S, то:\n1. Š является единственной минимальной формой с точностью до обозначения состояний\n2. Š=S\n3. Никакие два состояния Š не являются эквивалентными\n4. Не существует автомата, эквивалентного S и меньшего (с меньшим числом состояний), чем Š."
    },
    {
        "question": "Напиши определение правоконтекстной грамматики.",
        "answer": "____\n\nПравоконтекстная грамматика — это тип грамматики в теории формальных языков, где правила переписывания зависят от контекста символов, стоящих справа от переписываемого нетерминала. \nТакие грамматики формализуются следующим образом:\nПравило грамматики имеет вид: αAβ→αγβ, где A — это нетерминальный символ, α и β — строки из терминалов и нетерминалов, а γ — строка, которая заменяет A. \nВажно, что заменяемый символ A может быть переписан только в случае, если справа от него стоит строка β, что и придает контекстность правилам."
    },
    {
        "question": "Опиши алгоритм Кока-Янгера-Касами.",
        "answer": "____\n\nАлгоритм Кока-Янгера-Касами — алгоритм, позволяющий по слову узнать, выводимо ли оно в заданной КС-грамматике в нормальной форме Хомского. Любую КС-грамматику можно привести к НФХ, поэтому алгоритм является универсальным для любой КС-грамматики.\nШаги алгоритма:\n1. Инициализация таблицы:\n\nПусть строка w имеет длину n. Создаём двумерную таблицу T размером n×n, где T[i,j] будет содержать множество нетерминалов, которые могут породить подстроку строки w, начиная с позиции i и имеющую длину j.\n\n2. Заполнение таблицы для подстрок длины 1:\n\nДля каждой подстроки длиной 1 (каждого символа строки), если есть правило вида A→a, где a — символ подстроки, то заполняем соответствующую ячейку таблицы T[i,1] нетерминалом A. Это инициализирует таблицу, заполняя её для самых маленьких подстрок (индивидуальных символов).\n\n3. Заполнение таблицы для подстрок большей длины:\n\nДля каждого l от 2 до n (длина подстроки), для каждой позиции i (начальная позиция подстроки) и для каждой k от 1 до l−1, проверяем возможные разбиения подстроки на две части.\nЕсли есть правило A→BC в грамматике, и если нетерминал B может породить левую часть подстроки (то есть T[i,k] содержит B), а C может породить правую часть подстроки (то есть T[i+k,l−k] содержит C), то добавляем A в T[i,l].\n\n4. Результат:\n\nЕсли в ячейке T[1,n] (которая соответствует всей строке длины n) содержится стартовый символ грамматики, то строка принадлежит языку. В противном случае строка не может быть порождена грамматикой."
    },
    {
        "question": "Напишите определение леммы о разрастании в общем виде.",
        "answer": "____\n\nЕсли язык L является регулярным, то существует число n⩾1 такое что для любого слова uwv из языка L, где |w|⩾n может быть записано в форме uwv=uxyzv, где слова x, y и z такие, что |xy|⩽n, |y|⩾1 и ux(y^i)zv принадлежит языку L для любого целого числа i⩾0."
    },
    {
        "question": "Контекстно-свободная (КС) грамматика это",
        "answer": "____\nКС грамматика - это грамматика, у которой в левых частях всех правил стоят только одиночные нетерминалы.\nЯзык, задаваемый контекстно-свободной грамматикой, называется контекстно-свободным языком.\nКС-грамматика: G = <N, ∑, P, S>, где правила имеют вид: A → β, где β ∈ (N + ∑)*"
    },
    {
        "question": "Левосторонний (Левый) вывод в КС грамматике это",
        "answer": "____\nВывод в КС-грамматике левосторонний (левый), если на каждом шаге вывода заменяется самое левое из всех вхождений нетерминальных символов, \nто есть каждый шаг вывода имеет вид: uAθ —> uβθ, где (A → β) ∈ P, A ∈ N и θ ∈ (N U ∑)*, u ∈ ∑*.\nЛевосторонний вывод однозначно восстанавливается по дереву вывода."
    },
    {
        "question": "Леворекурсивная КС грамматика это",
        "answer": "____\nЛеворекурсивная грамматика - это грамматика, в которой есть нетерминал, который может быть заменен на себя самого в левом направлении, то есть грамматика, имеющая хотя бы один леворекурсивный нетерминал."
    },
    {
        "question": "Праворекурсивная КС грамматика это",
        "answer": "____\nПраворекурсивная грамматика - это грамматика, в которой есть нетерминал, который может быть заменен на себя самого в правом направлении, то есть грамматика, имеющая хотя бы один праворекурсивный нетерминал."
    },
    {
        "question": "Рекурсивная КС грамматика это",
        "answer": "____\nРекурсивная грамматика - это грамматика,  в которой все нетерминалы рекурсивные (кроме, может быть, S)."
    },
    {
        "question": "Бесполезный символ (нетерминал) в КС грамматике это",
        "answer": "____\nСимвол D (нетерминал) - бесполезный, если в грамматике нет вывода вида S → *wDy → *wvy, где v, w, y ∈ ∑*"
    },
    {
        "question": "Неукорачивающая КС грамматика это",
        "answer": "____\nНеукорачивающая КС грамматика -  это грамматика, которая может производить бесконечно длинные строки, то есть грамматика без ε-правил. Пример неукорачивающей КС грамматики: S → aSb | a."
    },
    {
        "question": "КС грамматика с цепным правилом это",
        "answer": "____\nКС грамматика с цепным правилом - это КС грамматика, в которой есть правило вида A → B, где A, B ∈ N. Имеет правило замены, которое содержит цепочку нетерминалов.\nПример КС грамматики с цепным правилом: \nS → aBb | ε\nB → bB | a"
    },
    {
        "question": "КС грамматика без циклов",
        "answer": "____\nКС грамматика без циклов - это КС грамматика, в которой нет правила: A → +A. То есть грамматика, которая не содержит циклов (кроме возможных циклов в терминальных символах), то есть, нетерминалы не могут быть заменены на себя самого через любое количество шагов.\nПример КС грамматики без циклов:\nS → aAb | ε\nA → b | c"
    },
    {
        "question": "Приведённая КС грамматика это",
        "answer": "____\nПриведённая КС грамматика - это грамматика без циклов, без бесполезных символов и без цепных правил."
    },
    {
        "question": "Алгоритм удаления бесполезных (непорождающих) символов в КС грамматике",
        "answer": "____\n1. Берём все правила, в правой части которых есть хотя бы один терминал. Берём оттуда\nмножество всех терминалов и нетерминалов слева.\n2. Берём все правила, в правой части которых встречаются нетерминалы только из нашего\nмножества. Добавляем нетерминалы слева в наше множество. Повторяем.\n3. На каком то шаге множество стабилизируется (все выводимые правила будут учтены). В нашем\nмножестве остались терминалы и все небесполезные нетерминалы.\n4. Берём разность всех нетерминалов и нетерминалов из нашего построенного множества. Это\nбудут бесполезные нетерминалы.\n5. Удаляем все правила, в которых встречаются бесполезные нетерминалы"
    },
    {
        "question": "Алгоритм удаления недостижимых символов",
        "answer": "____\n1. Берём множество, состоящее из S.\n2. Добавляем в наше множество все нетерминалы и терминалы, которые стоят в правой части\nправил, в левой части которых нетерминалы из нашего множества.\n3. На каком-то шаге множество стабилизируется (все выводимые правила будут учтены). В нашем\nмножестве остались только достижимые символы (терминалы и нетерминалы).\n4. Берём разность всех нетерминалов и нетерминалов из нашего построенного множества. Это\nбудут бесполезные нетерминалы. То же самое и с терминалами.\n5. Удаляем все правила, в которых встречаются бесполезные нетерминалы. То же самое и с терминалами."
    },
    {
        "question": "Алгоритм удаления ε-правил",
        "answer": "____\n1. Нашли все ε-правила. Добавили в множество нетерминалы из левых частей этих ε-правил.\n2. Заменили во всех правилах нетерминалы из нашего множества на ε.\n3. Убрали все ε (ε^n = ε).\n4. Повторяем с шага 1, пока можем найти новые ε-правила.\n5. Для всех правил вида A → B, где для B существует ε-правило, добавим правила вида A → ε, если таких еще нет.\n6. Удаляем все изначальные ε-правила (т.е. те, которые нашли на 1-ом шаге)."
    },
    {
        "question": "Алгоритм удаления цепного правила",
        "answer": "____\nЕсли встретилось цепное правило A → B, и в P есть правило вида B → α, α ∈ (N + ∑)*, то добавим правило A → α, а правило A → B вычеркнем."
    },
    {
        "question": "Что такое язык Лукасевича",
        "answer": "____\nЯзыком Лукасевича над n + 1 буквами называется контекстно-свободный\nязык над алфавитом {a0, a1,...,an}, порождаемый грамматикой\nS -> a0, S -> a1S, S -> a2SS, ..., S -> anSn\nЗамечание: При любом n ∈ N грамматика является однозначной."
    },
    {
        "question": "Что такое язык Дика",
        "answer": "____\nЯзыком Дика над 2n\nбуквами называется контекстно-свободный язык над алфавитом\n{a1, b1, a2, b2,...,an, bn}, порождаемый грамматикой S → ε,\nS → a1Sb1S, ..., S → anSbnS.\nЗамечание: Словами этого языка являются последовательности правильно вложенных скобок n типов.\nЗамечание: При любом n ∈ N грамматика является однозначной."
    },
    {
        "question": "Что такое автомат Мили",
        "answer": "____\nАвтомат Мили - это 6-ка (Q, Σ, Λ, δ, λ, q₀), где:\nQ - множество состояний автомата\nΣ - конечный входной алфавит\nΛ - конечный выходной алфавит\nδ - функция перехода, которая принимает текущее состояние и входной символ, и возвращает следующее состояние\nλ - функция вывода, которая принимает текущее состояние и входной символ, и возвращает выходной символ\nq₀ - начальное состояние"
    },
    {
        "question": "Какие есть свойства у класса детерминнированых контекстно-свободных языков",
        "answer": "____\nТеорема: Каждый автоматный язык является детерминированным контекстно-свободным языком.\nТеорема: Язык L ⊆ Σ∗ является детерминированным\nконтекстно-свободным языком тогда и только тогда, когда\nнайдётся такой детерминированный МП-автомат M' = <Q', Σ, Γ', ∆', I', F'>, что\nL={w∈Σ∗ | <s,w,ε> |*-- <q,ε,α> для некоторых s∈I', q∈F', α∈Γ'∗}.\nТеорема: Пусть L — детерминированный контекстно-свободный язык. Тогда язык L не является существенно\nнеоднозначным.\nТеорема: Дополнение каждого детерминированного\nконтекстно-свободного языка является детерминированным\nконтекстно-свободным языком.\nПример 12.10. Язык L = {a^kb^mc^n | k != m или m != n}\nнад алфавитом {a, b, c} не является детерминированным контекстно-свободнымязыком, так как его дополнение не является\nконтекстно-свободным\nТеорема: Неверно, что для любых детерминированных контекстно-свободных языков L1 и L2 язык L1 ∩ L2\nтоже является детерминированным контекстно-свободным\nязыком.\nТеорема: Неверно, что для любых детерминированных контекстно-свободных языков L1 и L2 язык L1 ∪ L2\nтоже является детерминированным контекстно-свободным языком."
    },
    {
        "question": "Сформулируй теорему Клини",
        "answer": "____\nТеорема Клини: Язык L является регулярным тогда и только тогда, когда он является автоматным\nЯзык L называется автоматным, если существует конечный автомат, распознающий этот язык."
    },
    {
        "question": "Что такое гомоморфизм афлавитов",
        "answer": "____\nПусть Σ1 и Σ2 — алфавиты. Если отображение h: Σ∗1 → Σ∗2 удовлетворяет условию h(x · y) = h(x)· h(y)\nдля всех слов x ∈ Σ∗1 и y ∈ Σ∗1, то отображение h называется\nгомоморфизмом (морфизмом).\nЗамечание: Если h — гомоморфизм, то h(ε) = ε.\nПример: Пусть Σ1 = {a, b} и Σ2 = {c}. Тогда\nотображение h: Σ∗1 → Σ∗2, заданное равенством h(w) = c^(2|w|), является гомоморфизмом.\nЗамечание: Каждый гомоморфизм однозначно определяется своими значениями на однобуквенных словах.\nОпределение 1.37. Если h: Σ∗1 → Σ∗2 — гомоморфизм и L ⊆ Σ∗1, то через h(L) обозначается язык {h(w) | w ∈ L}.\nПример: Пусть Σ = {a, b} и гомоморфизм h: Σ∗ → Σ∗ задан равенствами h(a) = abba и h(b) = ε. Тогда\nh({baa, bb}) = {abbaabba, ε}.\nОпределение 1.39. Если h: Σ∗1 → Σ∗2 — гом ом орфизм и L ⊆ Σ∗2, то через h^(−1)(L) обозначается язык {w ∈ Σ∗1 | h(w) ∈ L}.\nПример: Рассмотрим алфавит Σ = {a, b}. Пусть гом оморфизм h: Σ∗ → Σ∗ задан равенствами h(a) = ab и h(b) = abb.\nТогда h^(−1)({ε, abbb, abbab, ababab}) = {ε, ba, aaa}."
    },
    {
        "question": "Что такое алгоритм восходящего разбора",
        "answer": "____\nИз книги Ахо-Ульман.\nАлгоритм: Восходящий разбор с возвратами\nВход. КС-грамматика G = (N, S, P, S) без циклов и е-правил\n(все ее правила занумерованы от 1 до р) и входная цепочка\nw = a1a2.. ,аn (n>=1).\nВыход. Один обращенный правый разбор, если он сущест-\nсуществует, и слово «ошибка» в противном случае.\nМетод.\n(1) Произвольным образом упорядочить правила.\n(2) Алгоритм будет изложен в терминах 4-компонентных\nконфигураций, подобных тем, что использовались в алгорит-\nалгоритме 4.1. В конфигурации (s, i, аlf, bet)\n    (а) s представляет состояние алгоритма,\n    (б) i представляет текущую позицию входного указателя\n    (предполагается, что (n + 1)-м входным символом служит\n    правый концевой маркер $),\n    (в) аlf—содержимое магазина L1 (верх которого располо-\n    расположен справа)\n    (г) bet — содержимое магазина L2 (верх которого располо-\n    расположен слева).\n\nКак и раньше, алгоритм может находиться в одном из трех\nсостояний q, b или t. В магазине L1 будет храниться цепочка\nтерминалов и нетерминалов, из которой выводится часть вход-\nвходной цепочки, расположенная слева от входного указателя.\nВ магазине L2 будет храниться история переносов и сверток,\nнеобходимых для получения из входной цепочки содержимого\nмагазина L1,\n(3) Начальная конфигурация алгоритма —(q, 1$, е),\n(4) Сам алгоритм работает так. Начинаем с попытки приме-\nприменить шаг 1.\n\nШаг 1. Попытка свертки\n(q, i, alf*bet, gam) |-- (q,i,alf*A, j*gam)\nпри условии, что А->bet — правило из Р с номером j и bet пер-\nпервая правая часть в линейном упорядочении, определенном в (1),\nкоторая является суффиксом цепочки alfbet. Номер этого правила\nзаписывается в L2. Если шаг 1 применим, повторить его.\nВ противном случае перейти к шагу 2.\n\nШаг 2. Перенос\n(q,i,alf,gam) |-- (q, i+1, alf*ai, s*gam)\nпри условии, что i!=n+1. Перейти к шагу 1.\nЕсли i = n+1, перейти к шагу 3.\nПри выполнении шага 2 i-й входной символ переносится в\nверхнюю часть магазина L1, позиция входного указателя уве-\nувеличивается и в магазин L2 записывается s, чтобы указать, что\nсделан перенос.\n\nШаг 3. Допускание\n(q, n+1, $S, gam) |-- (t, n+1, $S, gam)\nВыдать h(y), где h — гомоморфизм, определенный равенствами\nh(s)=e, h(j) = j для всех номеров правил, h(у) — обращенный\nправый разбор цепочки w. После этого остановиться.\nЕсли шаг 3 неприменим, перейти к шагу 4.\n\nШаг 4. Переход в состояние возврата\n(q, n+1, alf, gam) |-- (q, i, alf'*B, k*gam)\nпри условии, что a!=$S. Перейти к шагу 5.\nШаг 5. Возврат\n(а) (b, i, alf*А, j*gam) |-- (q, i, alf'*B, k*gam)\nесли А—>bet — правило из Р с номером j, а следующим прави-\nправилом в упорядочении (1), правая часть которого является суф-\nсуффиксом цепочки аlf*bet, является правило В —> bet' с номером к.\n(Заметим, что alfbet~alf'bet'.) Перейти к шагу 1. (Здесь происходит\nвозврат к предыдущей свертке и делается попытка свертки с\nпомощью следующей альтернативы.)\n\n(б) (b, n+1, alf*A, j*gam) |-- (b, n+1, alf*bet, gam)\nесли А—>bet — правило из Р с номером j и для цепочки alf*bet не\nостается никакой другой свертки. Перейти к шагу 5. (Если дру-\nдругих сверток не существует, надо «взять назад» данную свертку\nн продолжать возврат, оставляя входной указатель на позициии n+1.) \n\n\n(в) (b, i, alf*A, j*gam) |-- (q, i + 1, alf*bet*a, s*gam)\nесли i!=n+1, А—>bet — правило из Р с номером j и для аlf*bet не\nостается никакой другой свертки. Здесь символ а = аl переносится в \nмагазин L1, а символ s поступает в L2. Перейти к шагу 1.\n(Мы вернулись к предыдущей свертке и,\nсверток нет, попробуем сделать перенос.)\n\n(г) (b, i alf*a, s*gam) |-- (b, i-1, alf, gam)\nесли наверху магазина L2 находится символ переноса s. (Здесь\nв позиции i исчерпаны все альтернативы и надо «взять назад»\nоперацию переноса. Входной указатель сдвигается влево, тер-\nтерминальный символ устраняется из L1, а символ переноса s —\nиз L2). Если этот шаг невыполним, объявить об ошибке.\nПример 4.4. Применим описанный алгоритм восходящего раз-\nразбора к грамматике G с правилами\n(1) E -> E+T\n(2) E -> T\n(3) T -> T*F\n(4) T -> F\n(5) F -> a\nЕсли наверху магазина L1 появится Е+Т, то сначала попы-\nпопытаемся сделать свертку, используя Е—>Е+Т, а потом — исполь-\nиспользуя Е—>Т. Если же появится Т*F, то сначала попробуем\nT->T*F, а потом T—>F. Для входа а*а восходящий алго-\nалгоритм пройдет через конфигурации\n(q,1,$,e) |-- (q,2,$a,s)\n          |-- (q,2,$F, 5s)\n          |-- (q,2,$T, 45s)\n          |-- (q,2,$E, 245s)\n          |-- (q,3,$E*, s245s)\n          |-- (q,4,$E*a, ss245s)\n          |-- (q,4,$E*F, 5ss245s)\n          |-- (q,4,$E*T, 45ss245s)\n          |-- (q,4,$E*E, 245ss245s)\n          |-- (b,4,$E*E, 245ss245s)\n          |-- (b,4,$E*T, 45ss245s)\n          |-- (b,4,$E*F, 5ss245s)\n          |-- (b,4,$E*a, ss245s)\n          |-- (b,3,$E*, s245s)\n          |-- (b,2,$E, 245s)\n          |-- (q,3,$T*, s45s)\n          |-- (q,4,$T*a, ss45s)\n          |-- (q,4,$T*F, 5ss45s)\n          |-- (q,4,$T, 35ss45s)\n          |-- (q,4,$E, 235ss45s)\n          |-- (t,4,$E, 235ss45s)"
    },
    {
        "question": "Что такое алгебра контекстно-свободных языков",
        "answer": "____\nАлгебраические свойства КС-языков:\nЕсли L — контекстно-свободный язык, то\nL∗ тоже контекстно-свободный язык.\nЕсли L1 и L2 — контекстно-свободные языки над алфавитом Σ, то L1 · L2 тоже контекстно-свободный\nязык.\nЕсли L1 и L2 — контекстно-свободные языки над алфавитом Σ, то L1 ∪ L2 тоже контекстно-свободный\nязык.\nЕсли L — контекстно-свободный язык, то\nL^R тоже контекстно-свободный язык.\nЕсли L — КС-язык, а R — регулярный язык, то L ∩ R — КС-язык.\nДополнение КС-языка в общем случае не является КС-языком."
    },
    {
        "question": "Что такое деревья вывода",
        "answer": "____\nВыводам в контекстно-свободной грамматике соответствуют так называемые деревья вывода (или деревья\nразбора) — некоторые упорядоченные деревья, вершины которых помечены символами алфавита N ∪Σ.\nКорень дерева отвечает начальному символу. Каждому символу слова w1, на которую заменяется начальный символ на первом\nшаге вывода, ставится в соответствие вершина дерева, и к ней\nпроводится дуга из корня. Полученные таким образом непосредственные потомки корня упорядочены согласно порядку их меток\nв слове w1. Для тех из полученных вершин, которые помечены символами из множества N, делается аналогичное построение\nи т. д. Кроной дерева вывода называется слово, записанное в\nвершинах, помеченных символами из алфавита Σ.\nПример: Рассмотрим контекстно-свободную грамматику\nS -> SS, S -> ab, S -> aSb. Выводу S -> SS -> Sab -> SSab -> abSab -> ababab соответствует следующее дерево вывода:\n        S\n       / \\\n      S   S\n     / \\  |\\\n    S   S a b\n   /|   |\\\n  a b   a b"
    },
    {
        "question": "Что такое неукорачивающиеся грамматики",
        "answer": "____\nОпределение: Порождающая грамматика называется\nнеукорачивающей, если для каждого правила (α -> β) ∈ P\nвыполняется неравенство |α| <= |β|.\nТеорема: Существует алгоритм, позволяющий по\nпроизвольной неукорачивающей грамматике G и по слову w\nузнать, верно ли, что w ∈ L(G).\nТеорема: Каждая контекстная грамматика является неукорачивающей. Каждая неукорачивающая грамматика\nэквивалентна некоторой контекстной грамматике.\nПример: Грамматика S -> AST A, S -> AbA, A -> a,\nbT -> bb, AT -> TA эквивалентна контекстной грамматике S -> ASTA, S -> AbA, A -> a,\nbT -> bb, AT -> UT, UT -> UV, UV -> TV, TV -> TA."
    },
    {
        "question": "Перечисли свойства регулярных выражений",
        "answer": "____\nРегулярные выражения образуют ассоциативное полукольцо с операциями (0, +, 1, ·), то есть для любых\nрегулярных выражений e, f и g выполняются следующие тождества:\n1. e+f = f+e,\n2. e+0 = e,\n3. (e+f)+g = e+(f+g),\n4. e·1 = e,\n5. 1·e = e,\n6. (e·f)·g = e·(f·g),\n7. e·(f+g) = e·f+e·g,\n8. (f+g)·e = f·e+g·e,\n9. e·0=0,\n10. 0·e = 0.\nРавенство понимается как равенство языков, задаваемых\nрегулярными выражениями.\nДля любых регулярных выражений e и f\nвыполняются следующие тождества:\n1. e+e = e,\n2. (1+e+ee+ ... +e^(n−1))(e^n)∗ = e∗ для любого n >= 1,\n3. (e∗f)∗e∗ = (e+f)∗,\n4. 1+e(fe)∗f = (ef)∗.\nЛемма: Для любых регулярных выражений e, f и g,\nесли e = ef+g и ε !∈ L(f), то e = gf∗."
    },
    {
        "question": "Что такое перевод конечного автомата в регулярное выражение",
        "answer": "____\nОпределение: Регулярное выражение над алфавитом Σ определяется рекурсивно следующимобразом: 0 является регулярнымвыражением; 1 является регулярным выражением; если\na ∈ Σ, то a является регулярным выражением; если e и f являются регулярными выражениями, то (e+f), (e·f) и e∗ тоже\nявляются регулярными выражениями. Вместо e·f часто пишут просто ef.\nПример. Пусть Σ = {a, b}. Тогда ((a·b)∗·(1+a)) является\nрегулярнымвыражениемнад алфавитом Σ.\nОпределение: Конечный автомат — это пятёрка M = <Q, Σ, ∆,I,F>, где\nΣ — конечный алфавит, Q и ∆ — конечные м ножества,\n∆ ⊆ Q × Σ∗ × Q, I ⊆ Q, F ⊆ Q. Элем енты Q называются состояниями, элементы I — начальными (initial) состояниями,\nэлементы F — заключительными или допускающими состояниями. Если <p, x, q> ∈ ∆, то <p, x, q> называется\nпереходом из p в q, а слово x — меткой этого\nперехода.\nПример: Пусть Q = {1, 2}, Σ = {a, b}, I = {2},\nF = {2}, ∆ = {<1, aaa, 1>, <1, ab, 2>, <1, b, 2>, <2, ε, 1>}. Тогда\n<Q, Σ, ∆,I,F> — конечный автом автомат.\nАлгоритм Томпсона (Данный алгоритм преобразовывает НКА в эквивалентный ДКА)\nАлгоритм преобразования ДКА в РВ:\nАлгебраический метод Бжозовского\nПри преобразовании ДКА в регулярное выражение создается система регулярных выражений \nдля каждого состояния в ДКА, а затем она решается для регулярных выражений Ri, связанных \nс терминальным состояниями qi. Построение уравнения происходит следующим образом: для каждого состояния qi уравнение Ri\nявляется объединением переходов, ведущих в это состояние. Переход a из qi в qj обозначается за aRi. Если qi\n- терминальное состояние, то в Ri добавляется ε. Это приводит к системе уравнений вида:\n\nR1=a1∗R1+a2∗R2+a3∗R3+...\nR2=a1∗R1+a2∗R2+a3∗R3+...+ε\n...\nRm=a1∗R1+a2∗R2+a3∗R3+...+ε\n\nгде ax = ∅ если нет перехода от Ri к Rj. Система может быть решена с помощью простой подстановки, \nза исключением случаев, когда неизвестное появляется как в правой, так и в левой части уравнения. \nДля этого можно воспользоваться теоремой Ардена:\n\nУравнение вида R=Q+RP, где P≠ε, имеет решение R=QP∗."
    },
    {
        "question": "Двоичное префиксное кодирование",
        "answer": "____\nэто гомоморфизм h : Σ+ → {0, 1}+ такой, что ∀ a, b ∈ Σ ∀ w ∈ {0, 1}∗(h(a) != h(b)w)."
    },
    {
        "question": "Формальная грамматика",
        "answer": "____\nэто способ описания формального языка, представляющий собой четверку\nΓ=⟨Σ,N,S∈N,P⊂((Σ∪N)∗N(Σ∪N)∗)×(Σ∪N)∗⟩, где:\nΣ — алфавит, элементы которого называют терминалами (англ. terminals);\nN — множество, элементы которого называют нетерминалами (англ. nonterminals);\nS — начальный символ грамматики (англ. start symbol);\nP — набор правил вывода (англ. production rules или productions) α -> β."
    },
    {
        "question": "Сентенциальная форма",
        "answer": "____\nэто последовательность терминалов и нетерминалов, выводимых из начального символа."
    },
    {
        "question": "Грамматика для правильной скобочной последовательности",
        "answer": "____\nΣ={(,)}\nS -> (S)\nS -> SS\nS -> ε"
    },
    {
        "question": "Регулярная (праволинейная) грамматика это",
        "answer": "____\nэто грамматика, которая содержит правила вида S -> ε (причем S не встречается в правых частях никаких правил), T_i -> a_i, T_i -> a_iT_j."
    },
    {
        "question": "G_1 и G_2 - праволинейные. Построить G: L(G) = L(G_1) U L(G_2) (объединение):",
        "answer": "____\n1. Переименовать нетерминалы из N_1 и N_2, чтобы стало N_1 ∩ N_2 = ∅ (сделать α-преобразование). Применить переименовку к правилам G_1 и G_2\n2. Объявить стартовым символом свежий нетерминал S и для всех правил G_1 вида S_1 -> α и правил G_2 вида S_2 -> β, добавить правила S -> α, S-> β в правила G\n3. Добавить в правила G остальные правила из G_1 и G_2."
    },
    {
        "question": "G_1 и G_2 - праволинейные. Построить G: L(G) = L(G_1)L(G_2) (конкатенация):",
        "answer": "____\n1. Переименовать нетерминалы из N_1 и N_2, чтобы стало N_1 ∩ N_2 = ∅ (сделать α-преобразование).\n2. Построить из G_1 ее вариант без ε-правил\n3. По всякому прваилу из G_1 вида A -> a строим правило G вида A -> aS_2, где S_2 - стартовый нетерминал G_2\n4. Добавить в правила G остальные правила из G_1 и G_2. Объявить S_1 стартовым\n5. Если ε ∈ L(G_1) (до шага 2), то по всем S_2 -> β добавить правило S_1 -> β."
    },
    {
        "question": "G_1 - праволинейная. Построить G: L(G) = L(G_1)+ (положительная итерация Клини):",
        "answer": "____\n1. Построить из G_1 её вариант без ε-правил\n2. По всякому правилу из G_1 вида A → a строим правило G вида A → aS_1, где S_1 — стартовый нетерминал G_1\n3. Добавить в правила G все (включая вида A → a) правила из G_1. Объявить S_1 стартовым\n4. Если ε ∈ L(G_1) (до шага 2), добавить правило S_1 → ε и вывести S1 из рекурсии"
    },
    {
        "question": "G — праволинейная. Построить G′ без правил вида A → ε такую, что L(G′) = L(G) или L(G′) ∪ {ε} = L(G):",
        "answer": "____\n1. Перенести в G′ все правила G, не имеющие вид A → ε\n2. Если существует правило A → ε, то по всем правилам вида B → aA дополнительно строим правила B → a."
    },
    {
        "question": "G_1, G_2 — праволинейные. Построить G′ такую, что L(G′) = L(G_1) ∩ L(G_2):",
        "answer": "____\n1. Построить стартовый символ G′ — пару ⟨S_1, S_2⟩, где S_i — стартовый символ грамматики G_i\n2. Поместить ⟨S_1, S_2⟩ в множество U неразобранных нетерминалов. Множество T разобранных нетерминалов объявить пустым\n3. Для каждого очередного нетерминала ⟨A_1, A_2⟩ ∈ U:\n\t- если A_1 → a ∈ G_1, A_2 → a ∈ G_2, тогда добавить в G′ правило ⟨A_1, A_2⟩ → a;\n\t- если A_1 → aA_3 ∈ G_1, A_2 → aA_4 ∈ G_2, тогда добавить в G′ правило ⟨A_1, A_2⟩ → a⟨A_3, A_4⟩, а в U — нетерминал ⟨A_3, A_4⟩, если его ещё нет в множестве T;\n\t- если все пары правил, указанные выше, были обработаны, тогда переместить ⟨A_1, A_2⟩ из U в T\n4 Повторять шаг 3, пока множество U не пусто\n5 Если ε ∈ L(G_1) & ε ∈ L(G_2), тогда добавить в G′ правило ⟨S_1, S_2⟩ → ε."
    },
    {
        "question": "Доказать теорема: Множество языков, задаваемых праволинейными грамматиками, совпадает со множеством языков, задаваемых конечными автоматами.",
        "answer": "____\nПусть имеется конечный автомат. Построим для него праволинейную грамматику. Множеством нетерминалов нашей грамматики будет множество состояний автомата. Для каждой пары состояний A и B такой, что имеется переход из A в B по символу c, добавим в грамматику правило A -> cB. Затем для каждой пары состояний автомата A и B такой, что имеется переход из A в B по символу c, и B является допускающим состоянием в автомате, добавим в грамматику правило A -> c.\n\nДокажем, что если для автомата верно ⟨S,α⟩⊢∗⟨U,ε⟩, то для построенной грамматики верно S⇒∗αU. Будем доказывать индукцией по переходам в автомате.\nБазой индукции будут переходы за 0 шагов.\nИндукционный переход: пусть данное свойство выполняется для переходов длины k−1. Докажем, что верно и для переходов за k шагов.\nРассмотрим переход ⟨S,α⟩⊢k⟨U,ε⟩, а именно его последний шаг: ⟨S,α⟩⊢k−1⟨Q,c⟩⊢⟨U,ε⟩.\nТак как для k−1 шага верно, то S⇒k−1αc−1Q, но по построению грамматики имеется правило Q -> cU, значит S⇒k−1αc−1Q⇒αc−1cU=αU. Таким образом, доказали для k шагов.\n\nДокажем в обратную сторону, а именно из S⇒∗αU следует ⟨S,α⟩⊢∗⟨U,ε⟩. Доказательство также проведем по индукции. Индукция будет идти по количеству примененных подряд правил.\nБазой индукции будут строки, выводимые в грамматике из начального нетерминала S за 0 применений правил.\nИндукционный переход: пусть верно для k−1 применения правил. Рассмотрим произвольную строку, полученную за k применений правил. Рассмотрим последнее применение правила. Если оно имело вид A -> aB, значит в автомате возможен переход ⟨A,a⟩⊢⟨B,ε⟩, а если A -> a, то B является допускающим в автомате. Таким образом, свойство выполняется для k последовательно примененных правил. Эквивалентность языков автомата и грамматики доказана.\n\nТеперь пусть имеется праволинейная грамматика. Построим по ней конечный детерминированный автомат. Введём специальное допускающее состояние ok. Множеством состояний автомата будет множество нетерминалов грамматики вместе с состоянием ok(Q=N∪ok). Для правил вида A -> aB определим функцию перехода в автомате как δ(A,a)=B. Для правил вида A -> a определим функцию перехода в автомате как δ(A,a)=ok.\n\nДокажем, что если слово выводится в грамматике, то оно допускается автоматом. Рассмотрим последовательность применений правил, дающую слово α длины k. Для каждого правила вида A -> aB в автомате существует переход из состояния A в состояние B по символу a. Таким образом, если после k−1 применения правил мы можем получить строку вида αc−1B, то в автомате имеется соответствующая последовательность переходов ⟨S,α⟩⊢k−1⟨B,c⟩, а поскольку можно вывести α, то хотя бы для одной строки такого вида существует правило B -> c, а значит в автомате есть переход ⟨B,c⟩⊢⟨ok,ε⟩. Таким образом автомат допускает слово α.\n\nДокажем, что если слово допускается автоматом, то его можно вывести в грамматике. Рассмотрим слово α длины k. Рассмотрим какую-либо последовательность переходов автомата, допускающую данное слово ⟨S,α⟩⊢k⟨ok,ε⟩. Для каждого одношагового перехода в автомате существует соответствующее правило в грамматике. Значит для подпоследовательности переходов из k−1 шага ⟨S,α⟩⊢k−1⟨U,c⟩ существует соответствующая последовательность применений правил S⇒k−1αc−1U. Для последнего перехода в автомате ⟨U,c⟩⊢⟨ok,ε⟩ существует правило U⇒c. Таким образом, существует последовательность применений правил грамматики, выводящая слово α."
    },
    {
        "question": "Автоматы называются изоморфными",
        "answer": "____\nесли существует биекция между их вершинами такая, что сохраняются все переходы, терминальные состояния соответствуют терминальным, а начальные — начальным."
    },
    {
        "question": "Задано два детерминированных конечных автомата. Определить, изоморфны ли они друг другу. Гарантируется, что все состояния автоматов достижимы.",
        "answer": "____\nАлгоритм\nИз определения следует, что если автоматы изоморфны, то можно их состояния занумеровать одним способом так, что вершины из разных автоматов с одинаковыми номерами будут равны — то есть в каждом из этих двух состояний существует переход в какое-то состояние с таким же номером, что и переход по этой же букве в другом состоянии. Поэтому мы можем зафиксировать какую-то нумерацию, например, в порядке обхода в глубину по символам в лексикографическом порядке и просто проверить состояния с одинаковыми номерами на равенство. Если все состояния будут равны, то автоматы будут равны, в нашем случае будет следовать изоморфизм двух автоматов. Асимптотика алгоритма совпадает с асимптотикой обхода в глубину, то есть O(N+M), где N — суммарное число вершин в автоматах, M — суммарное число ребер.\n\nПсевдокод\nTransitions — множество пар ⟨a, T⟩ , где a∈Σ, T∈Q\nAssotiations — массив, где каждому состоянию первого автомата соответствует найденное состояние второго автомата.\n\nboolean dfs(u: Vertex, v: Vertex): \n   visited[u] = true   // заметим, что достаточно только одного массива visited на два автомата\n   \n   if (v.terminal != u.terminal)\n     return false   \n   associations[u] = v\n   boolean result = true\n   for (⟨c,q⟩ : u.transitions)      \n     Vertex t1 = u.transitions.getVertex(c)\n     Vertex t2 = v.transitions.getVertex(c)\n     if одна из вершин t1, t2 дьявольская, а другая — нет\n       return false\n     if (visited[t1]) \n       result = result and t2 == associations[t1]\n     else\n       result = result and dfs(t1, t2)                \n         \n   return result"
    },
    {
        "question": "Полукольцо S = ⟨A, ⊕, ⊗, 0⟩ над носителем A",
        "answer": "____\nэто алгебраическая структура такая, что:\nS — коммутативный моноид по ⊕;\nS — полугруппа по ⊗;\n0 — это id по сложению и ноль по умножению;\nвыполнены левая и правая дистрибутивности."
    },
    {
        "question": "Алгебра Клини ⟨Σ, |, ·, ∗, ∅, ε⟩",
        "answer": "____\nидемпотентное полукольцо с единицей, удовлетворяющее следующим аксиомам:\n1) x∗x + 1 = x∗ = 1 + xx∗(аксиома развёртки)\n2) (формализация Саломаа, Sal): ∀p, q, x ((p | qx = x ⇒ x = q∗p) & (p | xq = x ⇒ x = pq∗)), где q не распознаёт ε — левая и правая леммы Ардена;\n3) (формализация Козена, Koz): ∀p, q, x ((q | px <= x ⇒ p∗q <= x) & (q | xp <= x ⇒ qp∗ <= x)), где x <= y ⇔ x | y = y, x = y ⇔ x <= y & y <= x.\n\nАксиома -- Сокращение\nx | x = x -- (Idm)\nε | xx∗ = x∗,  ε | x∗x = x∗ -- (Unfold) \n(x | y)z = xz | yz, x(y | z) = xy | xz -- (Dstr) \nq | px <= x ⇒ p∗q <= x, q | xp <= x ⇒ qp∗ <= x -- (Koz)"
    },
    {
        "question": "Некоторые теоремы алгебры Клини и их приминения",
        "answer": "____\n(Bsm) ax = xb ⇒ a∗x = xb∗ (Бисимуляция)\n(Sld) x(yx)∗ = (xy)∗x (Сдвиг)\n(Dnst) x∗(yx∗)∗ = (x | y)∗ (Уплощение)\n\nЗаконы сдвига и уплощения используются в оптимизациях\nрегулярных событий: закон сдвига позволяет перестраивать циклы с поствычислениями в циклы с предвычислениями; закон уплощения позволяет перестраивать друг в друга вложенные циклы и циклы с условиями внутри итерации."
    },
    {
        "question": "Теорема о полноте Sal и Koz (формализация Саломаа и Козена)",
        "answer": "____\nЛюбое равенство регулярных выражений выводимо из аксиоматики Sal и аксиоматики Koz."
    },
    {
        "question": "Смысл леммы Ардена и Козена",
        "answer": "____\nНеподвижная точка функции f(x) — такое x, что f(x) = x.\nПусть X = (pX) | q, где X — неизвестное RE, а p, q — известные, причём ε не принадлежит L(p). Тогда X = (p)∗q.\nТо есть p∗q — наименьшая (но не единственная) неподвижная точка выражения px | q по отношению <=, и единственная, если ε не принадлежит L(p).\nРассмотрим систему уравнений:\nX1 = (A_11X_1) | (A_12X_2) | . . . | B_1\nX2 = (A_21X_1) | (A_22X_2) | . . . | B_2\n. . .\nXn = (A_n1X_1) | (A_n2X_2) | . . . | B_n\nПоложим ε не принадлежит A_ij. Выразим X_1 через X_2, . . . , X_n, X_2 через X_3. . . X_n и т.д. Получим регулярное выражение для X_n (и после обратных подстановок также для X_n-1,. . . ,X_1)."
    },
    {
        "question": "формальные определения LR(k)-грамматик",
        "answer": "____\nLR(k)-грамматика - это вид грамматики, которая использует два вида productions (правил):\n1. Left-to-right (LR) - справа налево, где каждый символ справа в левой части правила должен быть заменен символом слева в правой части правила.\n2. Right-to-left (RL) - слева направо, где каждый символ слева в правой части правила должен быть заменен символом справа в левой части правила.\n\n LR(k)-грамматика имеет следующее формальное определение:\n\n* Начало грамматики: S\n* Контекст-независимые терминалы: T\n* Контекст-зависимые терминалы: V\n* Non-terminal symbols (символы не терминалов): N\n* Productions (правила): P\n\n LR(k)-грамматика определяется как 5-튜пл (S, T, V, N, P), где:\n\n1. S - начало грамматики (initial symbol)\n2. T - контекст-независимые терминалы (terminals)\n3. V - контекст-зависимые терминалы (non-terminals)\n4. N - не терминалы (non-terminals)\n5. P - productions (правила)\n\n LR(k)-грамматика называется к-ограниченной, если для любого правила P в грамматике существуют такие числа i и j, что:\n\n1. P: A → αβ, где α ∈ (V ∪ T)* и β ∈ (V ∪ T)k+1\n2. i ≤ |α| ≤ k и j ≤ |β| ≤ k+1\n\nВот несколько примеров LR(1)-грамматики:\n\n1. S → aA | bB\nA → aA | ε\nB → bB | ε\n\n2. S → aA | bB\nA → aAa | aa\nB → bBb | bb\n\nВ этих примерах LR(1)-грамматика определяется как 5-튜пл (S, T, V, N, P), где:\n\n* S - начало грамматики (initial symbol)\n* T - контекст-независимые терминалы (terminals): {a, b}\n* V - контекст-зависимые терминалы (non-terminals): {A, B}\n* N - не терминалы (non-terminals): {A, B}\n* P - productions (правила):\n\n1. P1: S → aA\nP2: S → bB\nP3: A → aA\nP4: A → ε\nP5: B → bB\nP6: B → ε\n\n LR(1)-грамматика используется в компиляторах для анализа синтаксиса языка программирования и для generation кода компилятора."
    },
    {
        "question": "Гарранитрует ли  LR(k)-грамматика однозначность разбора ?",
        "answer": "____\nLR(k)-грамматика не обязательно гарантирует однозначность разбора.\n\nLR(k)-грамматика — это тип грамматики, который обеспечивает левую рекурсию и является рекурсивным по правой части. Это означает, что LR(k)-грамматика может иметь правые рекурсивные правила, которые повторяются на каждой правой части, а также левую рекурсию, что означает, что правая часть может быть повторена в более глубокой грамматике. LR-обработчик (алийзер) использует для анализа вводимые к эндавардам.LR-предполагает, что анализ будет производиться шаг за шагом вправо, а использование не требуется.LR(к)-грамматика – это расширение LR-обработчика, которое поддерживает к-корпуса или c-корпуса в правой части правила. Это позволяет обработчику посмотреть на k символов вперед и принимать решения о том, следует ли продолжать анализ в текущем положении или сделать сброс.\n\nОднако LR(k)-грамматика не гарантирует однозначности разбора, поскольку грамматика может иметьAmbiguous syntax илиConflicting parses. Это означает, что может быть несколько возможных синтаксических анализов того же потока символов. В таких случаях LR-обработчик должен использовать некоторую стратегию для выбора, какой анализ использовать или какие решения принять в связи с конфликтом.\n\nLR-обработчик может использовать стратегии, такие как FIRST/FOLLOW-приведение, шаблон первого случая, программирование двумя конфликтами и другие, чтобы справиться с случаями конфликта. Актуальность использования грамматики LR(к) в программе обработки определяется ее практическими потребностями."
    },
    {
        "question": "Лемма о накачке для DCFL",
        "answer": "____\nЛемма о принудительной накачке — фундаментная теорема в теории Formal Language, которая утверждает, что качество languages DCFL (Deterministic Context-Free Languages) эквивалентно TISP (Терминированным примитивным контекстно-свободным языкам), как перехватывающий. нужной неисчерпаемости, так и посылки с неисчерпаемостью.\n\nВ более формальном варианте, если L является DCFL, то существует TISP M, который разбивает L. Для определения деления M : \n- Start(S) : \nСмотри: \nМы утверждаем, что это эквивалентно.\nНачнем с демонстрации эквивалентности с неисчерпаемостью. Пусть L является TISP language, с которым не было выявлено. Если мы установим non-deterministic automate (NFA) M, который разделяет L, мы можем построить determinstic automaton (DFA) D, который также разделяет L, следующим образом. \n\nСначала создайте полный automate D определяемый отношениями деления M по следующему правилу: \nq0 ∈ Q if δ0^R (Например, делаем 0)\nिल = {q ∈ Q | ∃p ∈ Q : δ^* (p, a) = q, δ^* (q, b) = p}\nПроверьте, что автономный жезл удален и изначально имеет недетерминированный модификатор. Для каждой недетерминированной грани Define недетерминированную грань до определенного R по следующим правилам: \nил = {q ∈ Q | ∃p ∈ Q : δ^* (p, a) = q, δ^* (q, b) = p и q ∈ ψ_i}\naphael (например, агрегируем) в случае отсутствия какой-либо меджи q.\n\nИз Ki путём удаления недетерминированных обоих NFA D заменяет M. Поскольку GFSA M прихватала задачу принудительного помехи всего L, то ETSFA D также может принудительно помехить этой проблеме. Таким образом, существование решения задачи заключает в том, что L имеет решение задачи. \n\nДалее мы показываем, что, если L имеет решение задачи, то существует язык GFSA, разделенный L. \n\nИсходя из положения о принудительном раздвижении мы знаем, что имеется TISP G, которая разделяет L. От своего начала мы можем мыслить oG, которая также разделяет L. \n\nВ задаче хватает помехи, поэтому предположим, что заурядный автомат oG делает сейчас \nq0 ∈ Q с δ0^R (q0) s q0 и делает на открывающую точку.\nПоскольку помеха заключается в том, что помеха существует, существуют loG и liG в G, такие, что \nloG делает непостоянное изображение q и liG делает непостоянное изображение p. \n(i). nf. Пусть дфан выживет E_G и li_G делают np и ло.\nq тогда выбирает hq, вида(np делает постоянное значение q, поскольку причитающееся постоянное значение s самому q является непостоянным значением х. Тогда автомат дфан, основанный на виде cdSq,Q делает np делает непостоянное значение g, поскольку это значением р является постоянное значение g при случаях она делает непостоянное значение q. Таким образом, g делает непостоянное значение g в SFSA оG. Отсюда следует, что del имеет явную проблему L с помехой. \n\nМы показали, что L — TISP разделяет при правом упадке GFSA с помехой только тогда, когда L имеет решение задачи, и что существование решения эквивалентно. \n\nДалее мы хотим показать, что L – TISP разделяет при правом хирургическом GSV,only тогда, когда L имеет решение задачи. \n\nИсходя из положения о принудительном раздвижении мы знаем, что существует TISP G, которая разделяет L. Мы можем повторить процесс, продемонстрированный в разделе принудительного попеременного члена, и создать задачу GFSA деление, существенное решение. Остановитесь: \n\nМы утверждаем, что это эквивалентно. \n\nСначала мы покажем, что существование решения эквивалентно. \n\nПусть L является делением TISP, не хирургицизируемым в GSV. Поскольку будет мотивацией, мы решим задачу GSV с кусковыми елезами, разрешающими разрывы чисел и ротозейвами и пневматическими двигателями и рассмотрим только тогда, когда величины GFSA можно высвечивать через все времени. Мы также можем считать только версии GFSA G с любой дополнительной информацией и перестановками TISP, разделенные L. Если мы сбросим все пневматические аэродинамики у диспетчера, пневматические движители и инструменты ротозейра G с равноценным равенством (si для i = 1, 2), мы сможем всю работу нарисовать GSV как настройку в желаемой манере. Пусть GSV быть gsv_GSV с элементом деления q0 такое, что деление правилами менее q0 делает различные виды для некоторых a б. О создании внутреннего открывающего n и возможности его манипулирования \nВысказываем, что лучше всего либерализовать GFSA, поскольку GFSA будет делить все числа. Это означает, что все решения GSV будет манипулировать p>0 тем, что x оба они с фотографией, заполняя все постоянные значения недетерминированного значения A, создавая рооль и здесь доказательства. \n\nПусть Q наконец будет набором первых 5 первых значений Q, и пусть К будет хотя бы каким-либо первым. Пусть матрица либо be другой тогда весь коллектив А ГСВ ГФСА.\n\nТеперь, поскольку L имеет решения в PVS при отказе, мы можем получить любое решение GSV следующим образом: у нас есть q0, которым будет пневматический ротозей в диспетчере к GSV. Пусть дала функция q0а, q0b удовлетворяет случаям действия q0A. \n\nПоскольку q0а делает отдельные операции ротозейными в GSV и r асе долгое время не использует двигатель, мы можем конфигурировать r A взять гейма, имеющего полный второй критерий.\nВходить 6 различных значений в GSV A. Здесь различные состояния, связанные с операциями ротозеймой, ротозеймой. могут быть определены через рассмотрение означения аага деления. \n\nБолее того, как говорит r разрыв, разрыв всегда в некотором отдельном ритме сохраняет варианты g — варианты вариантов ротозейма при некотором ограничении изменения разрыва, которое нужно показать для показа этой возможности.. \n\nКроме того, поскольку последовательные преобразования A принимают постоянное значение при агрегировании GSV, все возведения своих вариантов известных вариантов б будут постоянными для привлечения варианта демонстрации в конкретном делении окончательного значения б.\n\nЧтобы показать пневматический ротозей r агля, поскольку вопрос разделения возбуждает задачу GSV, возбуждая варианты разрыва номера длины GSV. \n\nНапример, некоторые g пара ГФСА может иметь GSV длиной не более 5ми числе разбойников. Затем (поскольку сконструирован только взрывной автозамок) у нас есть q0b = <*, p>, где единственное ограничение: \nна возможность меняется q0b — поскольку это только постоянные значения для непостоянных значений r г. \n\nСюда включено создание решения GSV следующим образом: если r GSV — вариант p ГФСА делит q0 на внутренний параметр H ГСВ, вместо него делит p ГФСА с новым значением на. внутренний аргумент г. \n\nС помощью пар gSV стоимостное решение может выполнить и ограничение q0b иметь постоянное значение и использовать привлеченные варианты продемонстрировать эквивалентное решение GSV. \n\nДалее мы хотим показать, что существование решения эквивалентно. \n\nПусть L — TISP разделенная PVS с хирургической операцией. Если мы задаем задачу GSV некоторой настройке G и создаем новую задачу GSV путем базового базового варианта как увеличения цен, обойденного взрывом, этой задачи, мы снова рассмотрим только тогда, когда варианты GFSA можно обежать через все время. Вырубаем динамический демонтированный старинный матерчатый перчаточный фартук. Пусть GSV будет sGSV с начальной версией q0, следующими правилами, позволяющими q0делить две проблемы за разрывом и r _,delving невозбужденные варианты разрыва ограничений навыков. \n\nСнова используя для защиты и определения описанную выше устроенность имея компоненты p, np, qо, qS, cdSq, Q, взрывной свиток, диспетчер, все информацию о контроллере, всеми инициаторами, всех ГФСА, p > 0, Х, е, у, подходит и сшитый гамбургер и все его остальные части, и пневматический ротозей r, создавая p > 0, которые правят ограничением q0b иметь постоянное значение GSV и использовать варианты, продемонстрировав эквивалентное решение GSV и создав решение с задержкой включенного аргумента. \n\nМы показали, что если L — TISP разделяет GSV с хирургической операцией, то существует решение задачи, и что существование решения эквивалентно. \n\nТеперь мы хотим показать, что L — TISP разделить GSV с принудительной накачкой тогда и только тогда, когда L имеет решение задачи. \n\nИсходя из положения о принудительном попеременном преобразовании мы знаем, что существует TISP G, которая разделяет L. Мы можем следовать процессу, продемонстрированному в разделе принудительного попеременного члена, и создать задачу GFSA деление, существенное решение. Остановитесь: \n\nМы утверждаем, что это эквивалентно. \n\nСначала мы покажем, что существование решения эквивалентно. \n\nПусть L является делением TISP, при котором не происходит попеременного попеременного ротация, разделив GSV. Поскольку будет мотивацией, мы решим задачу GSV с кусковыми елезами, разрешающими разрывы чисел и ротозеймами и пневматическими двигателями и рассмотрим только тогда, когда величины GFSA можно высвечивать через все время. Мы также можем считать только версии GFSA G с любой дополнительной информацией и перестановками TISP, разделенные L. Если мы сбросим все пневматические аэродинамики у диспетчера, пневматические движители и инструменты ротозейра G с равноценным равенством (si для i = 1, 2), мы сможем всю работу нарисовать GSV как настройку в желаемой манере. Пусть GSV быть gsv_GSV с элементом деления q0 такое, что деление правилами менее q0 делает различные виды для некоторых a б. О создании внутреннего открывающего n и возможности его манипулирования \nВысказываем, что лучше всего либерализовать GFSA, поскольку GFSA будет делить все числа. Это означает, что все решения GSV будет манипулировать p>0 тем, что x оба они с фотографией, заполняя все постоянные значения недетерминированного значения A, создавая рооль и здесь доказательства. \n\nПусть Q наконец будет набором первых 5 первых значений Q, и пусть К будет хотя бы каким-либо первым."
    },
    {
        "question": "Степень недетерминизма языка",
        "answer": "____\nЕсли PDA A допускает декомпозицию на DPDA, между\nкоторыми есть максимум k недетерминированных\nпереходов, но не допускает такую декомпозицию при i < k\nпереходов, скажем, что A задаёт КС-язык с\nk-недетерминированностью"
    },
    {
        "question": "Исправление недетерминированности КС языка",
        "answer": "____\nИсправление недетерминированности КС языка - это процесс, который позволяет преобразовать КС язык в детерминированный язык, сохранив его свойства и семантику.\n\nКС язык (Context-Sensitive language) - это язык, который может быть описан с помощью контекст-зависимых грамматик. КС языки имеют недетерминированность, что означает, что алгоритм, описывающий язык, не может быть однозначно определен.\n\nИсправление недетерминированности КС языка может быть выполнено с помощью следующих методов:\n\n1. **Determinization**: это процесс, который позволяет преобразовать КС язык в детерминированный язык, сохранив его свойства и семантику. Для этого используются алгоритмы, такие как алгоритм Курано, алгоритм Рейдера и т.д.\n2. **Regularization**: это процесс, который позволяет преобразовать КС язык в регулярный язык, сохранив его свойства и семантику. Для этого используются алгоритмы, такие как алгоритм Регулярного выражения и т.д.\n3. **Approximation**: это процесс, который позволяет приблизительно определить КС язык, сохранив его свойства и семантику. Для этого используются алгоритмы, такие как алгоритм APPROX и т.д.\n\nВ целом, исправление недетерминированности КС языка является важным шагом в разработке алгоритмов и автоматов для языков, которые имеют высокую степень недетерминированности.\n\nНекоторые примеры алгоритмов, которые могут быть использованы для исправления недетерминированности КС языка:\n\n* Алгоритм Курано (Curno's algorithm): это алгоритм, который позволяет преобразовать КС язык в детерминированный язык, используя контекст-зависимые грамматики.\n* Алгоритм Рейдера (Reeder's algorithm): это алгоритм, который позволяет преобразовать КС язык в детерминированный язык, используя контекст-зависимые грамматики и регулярные выражения.\n* Алгоритм APPROX (Approximation algorithm): это алгоритм, который позволяет приблизительно определить КС язык, используя регулярные выражения и контекст-зависимые грамматики.\n\nВ целом, исправление недетерминированности КС языка является важным шагом в разработке алгоритмов и автоматов для языков, которые имеют высокую степень недетерминированности."
    },
    {
        "question": "Переключающиеся автоматы (Alternating Finite Automata)",
        "answer": "____\nАльтернативные финиитные автоматы (Alternating Finite Automata, АФА) - это тип машин, которые могут быть использованы для определения языка регулярных выражений с использованием альтернативы.\n\nОбратите внимание, что в отличие от дDeterministic Finite Automata (ДФА), АФА не обязаны быть детерминированными, то есть переходы на следующий шаг могут быть выполнены в зависимости от результата выборки алфавита.\n\nМодель АФА:\n\n* Каждое состояние имеет несколько переходов на другие состояния, зависящее от выборки алфавита.\n* В каждом состоянии есть одна из двух возможностей: переход или остановка.\n* ВАФ может быть представлено в виде 6-типного троек: Q, Σ, δ, q0, F, и λ.\n\n* Q - множество состояний.\n* Σ - алфавит.\n* δ - функция перехода, которая maps (Q × Σ) → 2^Q.\n* q0 - начальное состояние.\n* F - множество финальных состояний.\n* λ - пустой символ.\n\nВ АФА есть две основные операции:\n\n1. Δ(q, a) - переход из состояния q в состояние δ(q, a).\n2. Σ(q) - остановка в состоянии q.\n\nМетка автомата определяется как множество состояний, из которых автомат может остановиться.\n\nПример:\n\nАльтернативный финиитный автомат для языка {a^i b^j | i, j ≥ 0} можно представить следующим образом:\n\nQ = {q0, q1}\nΣ = {a, b}\nδ = {(q0, a) → {q0, q1}, (q0, b) → ∅, (q1, a) → ∅, (q1, b) → {q0}}\nq0 = q0\nF = {q0}\n\nВ этом примере автомат имеет два состояния q0 и q1. В начальном состоянии q0, автомат может перейти в любое из состояний q0 или q1, если он выбирает а, или останавливаться, если он выбирает b. Если автомат находится в состоянии q1, он останавливается, если он выбирает а или b.\n\nМетка автомата - множество состояний, из которых автомат может остановиться, то есть {q0}.\n\nАльтернативные финиитные автоматы могут быть использованы для определения языка регулярных выражений с использованием альтернативы, а также для определения языка контекстно-свободных грамматик.\n\nОни также могут быть использованы для определения языка с использованием альтернативы в языке регулярных выражений, таких как {a^i b^j | i, j ≥ 0} или {a^i b^j c^k | i, j, k ≥ 0}."
    },
    {
        "question": "Теоретический коллапс линейных парсеров",
        "answer": "____\nТеоретический коллапс линейных парсеросов\n\nВ теоретической информатике коллапс линейных парсеросов - это явление, при котором ресурсов, необходимых для решения задачи, растет экспоненциально с размером входных данных. Это означает, что время выполнения алгоритма и потребление памяти быстро растут при увеличении размера входных данных, эффективно делая задачу неразрешимой.\n\nДавайте глубже исследуем это понятие.\n\n**Что такое парсерос?**\n\nВ контексте линейных систем парсерос - это класс языков, которые могут быть распознаны определенным типом конечного автомата, называемым линейным паритетом (LPA). LPAs оборудованы паметной лентой, разделенной на ячейки, каждая из которых хранит двоичный символ (0 или 1). Автомат начинает работу в начальном состоянии, читает входные символы по одному и перемещается между состояниями в соответствии с предопределенными правилами. На каждом шаге автомат читает текущее состояние, читает следующий символ и обновляет паметную ленту, записывая 0 или 1 в текущей ячейке.\n\n**Что такое коллапс?**\n\nТеперь imagine hypothetical ситуацию: Представьте себе ситуацию, когда задача P имеет уникальное решение в классе линейных парсеросов, то есть существует LPA, который может распознать все экземпляры P. Коллапс происходит, когда, несмотря на уникальное решение, становится очень трудно или компьютерно неосуществимо найти его.\n\nКоллапс происходит из-за ограничений LPAs в распознавании некоторых задач. Проблема возникает, когда язык является редким, то есть есть больше строк, не входящих в язык, чем тех, которые входят в него. В таких случаях, даже с уникальным решением, время и память, необходимые для его поиска, могут стать неосуществимыми при увеличении размера входных данных.\n\n**Ключевые характеристики:**\n\n1. **Уникальное решение**: Задача P называется уникальным решением, если существует LPA, который может распознать все экземпляры P.\n2. **Коллапс**: Когда решение становится компьютерно неосуществимым или требует много времени при увеличении размера входных данных, несмотря на уникальность.\n\n**Импликации:**\n\nКоллапс линейных парсеросов имеет значимые последствия для различных областей, таких как:\n\n1. **Теория сложности вычислений**: Он подчеркивает ограничения текущих алгоритмов и важность разработки новых, более эффективных подходов для решения неразрешимых задач.\n2. **Теория кодирования**: Коллапс освещает трудности в создании оптимальных кодов для надежной передачи и хранения данных.\n3. **Машинное обучение**: Исследователи могут потребовать разработки альтернативных методов для уменьшения влияния коллапса, что может привести к созданию новых алгоритмов и архитектур.\n\nХотя коллапс линейных парсеросов может казаться неожиданным вначале, он спровоцировал интересные направления исследований и глубоко расширил наше понимание ограничений в решении компьютерных задач."
    },
    {
        "question": "автомат Треллиса",
        "answer": "____\nВы упомянули автомат по типу Trelleborg!\n\nTrelleborg - это известная шведская компания, которая специализируется на разработке машин для изменяения шин, и их автоматическая машина для изменения шин - это популярный выбор для шинных станций и автоматизированных станций сервиса.\n\n以下 перечислены основные функции и преимущества автомата Trelleborg:\n\n1. **Удобство**: машина может изменить шину в считанные минуты, что значительно быстрее методов ручного изменения шин.\n2. **Точность**: машина спроектирована для обеспечения точного и-consistent наджима шины, что важно для безопасности и продолжительной службы шин.\n3. **Easy to use**: машина имеет пользовательский интерфейс, который сделает ее простой для использования даже для пользователей с ограниченным опытом изменения шин.\n4. **Контроль**: машина позволяет пользователю контролировать процесс изменения шины, обеспечивая ее правильное посадку и наджим.\n5. **Продолжительность жизни**: машина является стойкой к частым нагрузкам и спроектирована для работы многие годы с proper servicing.\n6. **Охрана окружающей среды**: машина уменьшает необходимость ручного труда, что может привести к уменьшению потребления топлива и выбросов.\n\nВ целом, автомат Trelleborg - это надежная и производительная машина, которая может помочь шинным станциям и автоматизированным станциям сервиса увеличить свою производительность и прибыльность, а также обеспечить безопасность и качество их услуг по изменению шин.\n\nХотите узнать больше о модели или функциях автомата Trelleborg?"
    },
    {
        "question": "Jumping Lemma",
        "answer": "____\nБорьба с Леммой!\n\nВ математике, особенно в топологии и анализе, Лемма о скачках (Jumping Lemma) - это результат, который обеспечивает нижнюю оценку скорости сходимости Certain функций. Специально, он работает с функциями, которые скачут неопределенно, такие как функция Хевисайда или функция абсолютного значения.\n\nЛемма обычно утверждает, что функция, имеющая скачковую дисконтинуацию в точке x, для точек y близких к x, будет иметь скорость сходимости, пропорциональную размеру скачки. Это means that function будет \"скачать\" обратно к своему ограничение, как y approches x, со скоростью, зависящей от размера скачки.\n\nЭто важное следствие имеет важные последствия в различных областях:\n\n1. Функциональный анализ: Лемма помогает понять свойства линейных операторов и их спектральное разложение.\n2. Теория меры: Он играет важную роль в исследовании мер и интегралов, особенно в контексте теории Лебега.\n3. Гармонический анализ: Лемма имеет приложения в анализе Фурье-серий и волокнистых преобразованиях.\n4. Теория приближений: Он обеспечивает оценку ошибки приближения функций при использовании приближений.\n\nУ вас есть какие-либо конкретные вопросы или темы, связанные с Леммой о скачках, которые вы хотели бы обсудить?"
    },
    {
        "question": "Атрибутные грамматики",
        "answer": "____\nАтрибутные грамматики (Attribute-Value Grammar, AVG) - это тип грамматики, который использует пару \"атрибут-значение\" (attribute-value) для определения синтаксических элементов языка.\n\nВ атрибутной грамматике, каждый синтаксический элемент языка ассоциирован с атрибутами, которые определяют его структуру и свойства. Атрибуты могут быть строковыми, целочисленными, логическими и другими типами данных.\n\nАтрибуты могут быть двух типов:\n\n1. Имя атрибута (Attribute Name) - это имя, которое задает атрибут. Например, \"type\", \"name\", \"date\".\n2. Значение атрибута (Attribute Value) - это значение, которое связано с именем атрибута. Например, \"int\", \"John\", \"2022-01-01\".\n\nАтрибуты используются для определения синтаксических правил языка, например:\n\n* \"sentence → (attribute: type, value: declarative) verb phrase (attribute: type, value: nominative) noun phrase (attribute: type, value: accusative)\"\n* \"verb phrase → (attribute: type, value: transitive) verb (attribute: type, value: tense, value: present) noun phrase (attribute: type, value: direct object)\"\n\nВ атрибутной грамматике, атрибуты используются для определения отношений между синтаксическими элементами языка, а также для задания ограничений на используемые значения атрибутов.\n\nАтрибутные грамматики могут быть использованы в различных приложениях, таких как:\n\n* Разработка языков программирования\n* Конструирование языков формализации\n* Синтаксическое разбиение текста\n* Определение языка запросов\n\nНедостатки атрибутных грамматик:\n\n* Комплексность: атрибутные грамматики могут быть сложными в описании и понимании\n* Несостоятельность: может быть трудно определить значения атрибутов в соответствии с синтаксическими правилами языка\n\nПримеры языков, использующих атрибутные грамматики:\n\n* SGML (Standard Generalized Markup Language)\n* XML (Extensible Markup Language)\n* HTML (Hypertext Markup Language)\n* SQL (Structured Query Language)\n\nВ целом, атрибутные грамматики предоставляют мощный инструмент для описания синтаксических правил языка, но могут быть трудны в использовании из-за своей сложности и потенциальной несостоятельности."
    },
    {
        "question": "Замкнута ли DMFL относительно пересечения с регулярным языком",
        "answer": "____\nОтвет на вопрос:\n\nНет, DMFL не обязательно замкнута относительно пересечения с регулярным языком.\n\nДля иллюстрации этого факта рассмотрим следующий пример:\n\nПусть L будет регулярным языком, признанным DMFL M, и пусть R будет регулярным языком, признанным DFA N. Пересечение L и R, обозначенное как L ∩ R, является регулярным языком, признанным DFA, который принимает слово, если и только если M принимает это слово и N принимает это слово.\n\nТеперь предположим, что M имеет более одного ленты, а R будет регулярным языком, который не может быть признан DFA (например, язык всех строк над алфавитом {a, b}, которые не содержат подстроки \"ab\"). Тогда пересечение L ∩ R не является регулярным языком, поскольку не может быть признано никаким DFA.\n\nОднако L ∩ R все еще может быть признан DMFL, поскольку M может симулировать поведение DFA на каждой ленте и затем интерсектировать результаты, чтобы определить, принимается ли слово. поэтому пересечение DMFL с регулярным языком не обязательно является регулярным языком.\n\nДействительно, пересечение DMFL с регулярным языком является контекстно-определенным языком, который является более общим классом языков, чем регулярные языки. Это потому, что DMFL может признать контекстно-определенный язык, симулируя поведение pushdown-автомата на каждой ленте.\n\nНадеюсь, это помогло! Если у вас есть дополнительные вопросы, пожалуйста, не стесняйтесь задавать их."
    },
    {
        "question": "Замкнута ли DMFL относительно объединения",
        "answer": "____\nDMFL (Data Markup Format Language) является замкнутым языком помаркирования для размечения и категоризации данных, в котором есть ограничения на возможности размечения, чтобы предотвратить неограниченное размечивание и обеспечить единство и понятность для размечения данных.\n\nВ частности, DMFL имеет несколько механизмов, чтобы помочь обеспечить ограничения и запреты на размечивание:\n\n1. Пользовательский профилювання: пользователи могут создавать имена для своих обрений, но ограничены до длины 64 символа.\n2. Документарное ограничение: пользователь не может создать объекты с именем, которое уже является документарным.\n3. Неупорядочивание: пользователь не может создавать ссылки на объекты, которые не существуют или не имеют определения.\n\nЭто ограничения позволяют предотвратить создание бесконечного или взаимосвязанного размечения и обеспечивают единство и понятность для размечения данных. DMFL также имеет built-in functions для проверки валидности размечивания, чтобы гарантировать, что разметка данных является правильной и корректной."
    },
    {
        "question": "Линеаризация регулярных выражений это",
        "answer": "____\n\nЕсли регулярное выражение r ∈ RE (регулярное выражение) содержит n вхождений букв алфавита ∑, тогда линеаризованное регулярное выражение Linearize(r) получается из r приписыванием i-ой по счёту букве, входящий в r, индекса i.\nРассмотрим регулярное выражение:(ba | b)aa(a | ab)*\nЕго линеаризованная версия:(b_1a_2 | b_3)a_4a_5(a_6 | a_7b_8)*"
    },
    {
        "question": "Множество First Last Follow",
        "answer": "____\n\nПусть регулярное выражение r ∈ RE (регулярное выражение), тогда:Множество First - это множество букв, с которых может начинаться слово из L(r) (если ε ∈ L(r), то оно формально добавляется в First);\nМножество Last- это множество букв, с которых может заканчиваться слово из L(r) \nМножество Follow(c)- это множество букв, с которых может предшествовать c. Т.е. { d ∈ ∑ | ∃ w_1, w_2 (w_1cdw_2 ∈ L(r)) }\nr = (ba | b)aa(a | ab)* - регулярное выражениеFirst(r) = {b}\nLast(r) = {a, b}\nFollow_r(a) = {a, b}; Follow)_r(b) ={a}"
    },
    {
        "question": "Минимализация ДКА алгоритм Хопкрофта",
        "answer": "____\nАлгоритм Хопкрофта для минимизации ДКА (Deterministic Finite Automaton) - это алгоритм, который позволяет найти минимальный ДКА, эквивалентный дадому ДКА.\nАлгоритм Хопкрофта работает следующим образом:\nШаг 1: Инициализация. Создаем начальное разделение на множество Q0 (начальные состояния) и множество Q1,..., Qn-1 (все другие состояния).\nШаг 2: Пока множество разделений более чем из одного элемента, выполняем следующее:\n* Выберите множество A из разделения.\n* Выберите символ c.\n* Для каждого множества B в разделении, разделите B на два подмножества:\n    * B_c: множество состояний в B, которые, прочитав c, переходят в состояние в A.\n    * B_~c: множество состояний в B, которые, прочитав c, не переходят в состояние в A.\n* Добавьте B_c и B_~c в разделение.\nШаг 3: Алгоритм останавливается, когда невозможно выполнить больше разделений.\nТеорема: Алгоритм Хопкрофта останавливается и производит минимальный ДКА.\nАлгоритм Хопкрофта является алгоритмом для поиска минимального ДКА, эквивалентного дадому ДКА, и используется в теории автоматов и регулярных языках."
    },
    {
        "question": "что такое LTS(Labelled Transition System)",
        "answer": "____\nLTS это тройка <S,∑,Q> где S-множество состояний, ∑ - множество меток, Q - множество переходов <троек из S x ∑ x S>. LTS похожи на автоматы но допускают бесконечные множества S и Q. так же в них нет начальных и финальных \nсостояний"
    },
    {
        "question": "Если язык L - регулярный, то он задаётся конечным недетерминированным автоматом. Докажи",
        "answer": "____\t\n\nПусть задан алфавит Σ терминальных символов.\nКак строятся регулярные множества, так же и доказывается теорема. Наша задача - доказать, что любое регулярное множество можно задать конечным недетерминированным автоматом. Для начала найдем схему построения автомата для регулярок-констант, т.е. для букв алфавита ∑, потом перейдем к усложнениям.\nПостроим автомат, который распознаёт некоторую букву а ∈ ∑:\nM = <Q, Σ, δ(x,y), q0, F>\nQ = {q0}\nF = {q0}\nδ(q0, a) = q0.\nТ.е. это автомат, распознающий язык {a}. Для языка { }, функция будет пустой, все остальное будет таким же. А для языка ∅ еще и множество допускающих состояний будет пустым, F = ∅.\nТут должен был быть рисунок с диаграммой, но его нет. Диаграмма автомата - обычный ориентированный граф, где вершины - состояния из Q, а те, что из F еще и как-то выделены цветом/обводкой/т.д. Ребро q1 → q2 всегда должно быть подписано буквой из a ∈ ∑, что означает, что (q1, a) = q2. Вот и все.\nНужно построить автомат, распознающий язык L1 + L2\nПо определению: Если языки L1 и L2 - регулярные, то и L1 + L2 - регулярный язык. Пусть L1 распознаётся автоматом M1=<Q1, Σ, δ1, q1, F1>, а L2 распознаётся автоматом M1=<Q2, Σ, δ2, q2, F2> Не ограничивая общности, считаем, что Q1∩Q2 =∅ (достигается обычным переименовыванием). Введём новое состояние q0.\nПусть M распознаёт L1+L2. M=<Q, Σ, δ, q0, F>\nQ=Q1UQ2U{q0}\nδ(q0, a) = δ1(q1,a) U δ2(q2,a)\nδ(q, a)= δ1(q, a); q∈Q1\nδ2(q, a), q∈Q2\nF = F1 U F2\nНужно построить автомат, распознающий язык L1 L2\nПусть M распознаёт L1L2. M=<Q, Σ, δ, q1, F>\nδ1(q, a), если q∈Q1\\F1\nδ(q, a)= δ1(q,a) U δ2(q2,a); q∈F1\nδ2(q, a), q∈Q2\nF=F2\n/здесь не все так просто - если q2 ∈ F2, то F = F1 ∪ F2/\nНужно построить автомат, распознающий язык L1*\nM=<Q, Σ, δ, q0, F>\nF=F1 U {q0}\nδ1(q1, a), если q=q0\nδ(q, a)= δ1(q, a); q∉F1\nδ1(q1,a) U δ1(q,a), q∈F"
    },
    {
        "question": "Если язык L - регулярный, то он задаётся праволинейной грамматикой. Докажи",
        "answer": "____\nS→ a — грамматика, из которой выводится 1 символ. Пустая грамматика соответствует пустому языку, а грамматика S → соответствует языку { }.\nПусть L1 и L2 - регулярные языки, и задаются грамматиками G1 и G2 соответственно.\nПостроим грамматику, которая задаёт язык L = L1 + L2:\nДобавим один новый нетерминал S: G=<N1 U N2, ∑, P, S>, где N1 - множество нетерминалов из G1, N2\n* множество нетерминалов из G2 Предположим, что N1∩N2=∅. P=P1U P2 и добавим новое правило: S → S1|S2 Построим грамматику, которая задаёт язык L=L1L2 Возьмём из P1 правила A → γ, где γ ∈ ∑*, и заменим их на правила A → γS2 Построим грамматику, которая задаёт язык L=L1\n* \nВозьмём все правила A → γ, где γ ∈ ∑*, и заменим их на правила A → γS1, а так же добавим правило S→"
    },
    {
        "question": "{a^nb^n| n>=0} is regular?",
        "answer": "____\n\n{a^nb^n| n>=0} is not regular. Let W = {a^k | k >=0}. For every distinct words a^i, a^j ∈ W (i !=j), we have b^i ∈ L^(a^i), but b^j !∈ L^(a^j)"
    },
    {
        "question": "{ww | w ∈ ∑* } regular?",
        "answer": "____\n\n{ww | w ∈ ∑* } is not regular. Let W=Σ*. For every 2 distinct words w, v ∈ W (w !=v), we have that w ∈ L^w, but w !∈ L^v"
    },
    {
        "question": "1) Лемма о накачке для регулярных языков.",
        "answer": "____\nПусть L регулярный язык. Тогда существует целое p ≥ 1 зависящее только от L, такое что строки w из L длины по меньшей мере p (p называется «длиной накачки») может быть записано как w = xyz, так что:\n1. |y| ≥ 1\n2. |xy| ≤ p\n3. для всех i ≥ 0, x(y^i)z ∈ L\ny — это подстрока, которую можно накачать (удалить или повторить произвольное число раз, так что результат останется в L). (1) означает, что цикл y должен быть накачан хотя бы длиной 1, (2) означает, что цикл должен быть в пределах первых p символов. На x и z ограничений не накладывается."
    },
    {
        "question": "2) Неформальное утверждение и пояснение леммы о накачке для регулярных языков.",
        "answer": "____\n\nЛемма о накачке описывает существенное свойство регулярных языков. Она утверждает, что слово w языка L длины по меньшей мере m, (где m константа, называемая длиной накачки, зависит лишь от L) можно разделить на три подстроки, w = xyz, так что среднюю часть, y (непустую), можно повторить произвольное число раз (включая ноль, то есть удалить) и получить строку из L. Этот процесс повторения называется «накачкой». Более того, лемма о накачке гарантирует, что длина xy не превысит m, ограничивая способы разделения строки w. Заметим, что конечные языки удовлетворяют требованиям леммы о накачке тривиально определяя m длиной максимальной строки из языка плюс один."
    },
    {
        "question": "3) Использование леммы о накачке для регулярных языков.",
        "answer": "____\nЛемма о накачке часто используется для доказательство того, что некоторый язык не является регулярным: доказательство от противного (предположив регулярность языка) может состоять из нахождения слова (нужной длины) языка, для которого свойство из формулировки леммы не выполняется.\n\nНапример нерегулярность языка L = {(a^n)(b^n) : n ≥ 0} над алфавитом Σ = {a, b} можно показать следующим образом. Пусть w, x, y, z, p, и i заданы соответственно формулировке леммы выше. Пусть w из L задаётся как w = (a^p)(b^p). По лемме о накачке, существует разбиение w = xyz, где |xy| ≤ p, |y| ≥ 1, такое что x(y^i)z принадлежит L для любого i ≥ 0. Если допустить, что |xy|=p, а |z|=p, то xy — это первая часть w, состоящая из p последовательных экземпляров символа a. Поскольку |y| ≥ 1, она содержит по меньшей мере одну букву a, а x(y^2)z содержит больше букв a чем b. Следовательно, x(y^2)z не в языке L (заметим, что любое значение i не равно 1 даст противоречие). Достигнуто противоречие, поскольку в этом случае накачанное слово не принадлежит языку L. Следовательно предположение о регулярности L неверно. Следовательно L — не регулярный язык.\n\nДоказательство нерегулярности языка сбалансированных скобок проводится с той же идеей. Если дано p, существует строка сбалансированных скобочек, начинающихся с более чем p левых скобок, так что y будет содержать только левые скобки. Повторяя y, можно сконструировать строку, в которой не содержится равное количество левых и правых скобок, которая не может быть сбалансированной."
    },
    {
        "question": "4) Доказательство леммы о накачке",
        "answer": "____\nПусть L — регулярный язык. Тогда по определению регулярности для языка L существует детерминированный конечный автомат (ДКА), который распознает этот язык. Пусть этот автомат имеет p состояний.\n\nТеперь рассмотрим любую строку w из языка L, длина которой |w| ≥ p. По принципу Дирихле (или \"принципу ящиков\"), если мы будем обрабатывать строку w на этом конечном автомате, то при обработке первых p символов строки автомат, проходя по состояниям, обязательно хотя бы одно состояние посетит дважды (поскольку всего состояний p, а символов в строке тоже p или больше).\n\nТаким образом, строку w можно представить в виде трёх частей:\nw = xyz, где:\n 1. x — часть строки, которая ведёт автомат от начального состояния до какого-то состояния;\n 2. y — часть строки, которая соответствует циклу в автомате (повторный визит в одно и то же состояние);\n 3. z — остаток строки после выхода из цикла.\nИз этого представления следует выполнение следующих условий:\n\n1. |y| ≥ 1, потому что y — это непустая часть строки, которая вызывает цикл, иначе повторного посещения одного и того же состояния не было бы.\n2. |xy| ≤ p, потому что цикл происходит в пределах первых p символов строки.\n3. Для всех i ≥ 0, строка вида x(y^i)z тоже принадлежит языку L. Это означает, что мы можем повторять или убирать часть y (которая соответствует циклу в автомате) произвольное количество раз, и полученная строка всё равно будет распознаваться автоматом, следовательно, принадлежать языку L.\nТаким образом, лемма о накачке утверждает, что для любой строки w длиной |w| ≥ p из регулярного языка можно найти разбиение w = xyz, которое удовлетворяет вышеуказанным условиям, что и завершает доказательство."
    },
    {
        "question": "5) Обобщённая лемма о накачке для регулярных языков",
        "answer": "____\nЕсли язык L регулярен, то существует число p > 0 (длина накачки), такое что для любой строки uwv из L с |w| ≥ p справедливо представление uwv = uxyzv\nгде x, y и z — строки, такие что |xy| ≤ p, |y| > 0 и ux(y^i)zv принадлежит L для любого целого i ≥ 0.\nЭту версию можно использовать для доказательства нерегулярность ещё большего числа языков, так как она накладывает более строгие ограничения."
    },
    {
        "question": "6) Недостаточность леммы о накачке для регулярных языков",
        "answer": "____\nЛемма о накачке для регулярных языков — это мощный инструмент для доказательства того, что язык не является регулярным. Однако она имеет ограничения: даже если язык нарушает условия леммы о накачке, это не всегда означает, что он нерегулярен. Лемма не всегда достаточна для доказательства регулярности или нерегулярности языка. Рассмотрим это на примере языка L:\nL={uvwxy:u,y∈{0,1,2,3}∗,vwx∈{0,1,2,3}∧(v=w∨v=x∨x=w)}∪{w:w∈{0,1,2,3}∗}\n\nРассмотрим структуру языка:\n1. Первая часть языка:\n   Это строки uvwxy, где:\n   \tu, y — произвольные строки из {0,1,2,3},\n\tvwx — строка длины 3 из {0,1,2,3},\n\tодно из условий выполняется: v = w, v = x или x = w (хотя бы два символа из vwx совпадают).\n2. Вторая часть языка:\nЭто все строки из {0,1,2,3}, то есть любой возможный набор символов.\n\nПопробуем применить лемму к языку L:\n1. Строки вида uvwxy имеют строгие ограничения на то, как символы v, w и x могут быть связаны между собой (они должны содержать хотя бы два одинаковых символа). Это может потребовать от конечного автомата \"памяти\", чтобы сравнить символы v, w и x, что может привести к нерегулярности языка.\n2. Однако из-за второй части языка (все строки из {0,1,2,3}) лемма о накачке будет бессильна. Любая строка из этой второй части удовлетворяет условиям леммы о накачке, так как она полностью регулярна (конечный автомат может распознать любые строки из {0,1,2,3}). Лемма просто не сможет доказать нерегулярность, потому что вторая часть языка охватывает все строки, которые можно \"накачать\", даже если первая часть не является регулярной.\n\nПочему лемма недостаточна для языка L:\n1. Если мы попытаемся применить лемму о накачке к языку L, она может \"провалиться\" на примерах из второй части языка (где любые строки регулярны). То есть лемма не сможет выявить нерегулярность первой части, так как регулярные строки из второй части будут удовлетворять условиям накачки.\n2. Лемма о накачке не может доказать нерегулярность языка, если в языке присутствуют регулярные составляющие, которые позволяют любым строкам \"успешно пройти\" проверку на условия леммы.\n\nВывод:Лемма о накачке недостаточна для доказательства нерегулярности языка L, поскольку вторая часть языка ({w : w ∈ {0,1,2,3}^*}) состоит из всех строк из {0,1,2,3}, которые всегда удовлетворяют условиям накачки. Это мешает применению леммы для доказательства нерегулярности первой части языка, связанной с условием совпадения символов в строке vwx."
    },
    {
        "question": "7) Делинеаризация регулярных выражений",
        "answer": "____\nДелинеаризация регулярных выражений — это процесс обратный линеаризации, который заключается в преобразовании регулярных выражений из линейной, упрощенной формы в более компактную или структурированную форму, обычно с использованием группировок и повторений для уменьшения объема кода и лучшего представления логики регулярного выражения. Делинеаризация помогает восстановить исходную структуру регулярного выражения, делая его более организованным и легко поддерживаемым."
    },
    {
        "question": "8) Зачем нужна делинеаризация?",
        "answer": "____\n1. Компактность: Линейные регулярные выражения, особенно если они содержат много альтернатив или повторяющихся частей, могут стать громоздкими. Делинеаризация помогает сократить объем выражения и улучшить его читаемость.\n2. Повышение читаемости: Делинеаризация добавляет структуру регулярному выражению. Сгруппированные части могут помочь лучше понять логику выражения, особенно когда разные части разделены на логические компоненты.\n3. Поддерживаемость: Регулярное выражение, состоящее из множества линейных альтернатив, сложно поддерживать и модифицировать. Группировка общих частей и использование сокращений делает выражение проще для внесения изменений в будущем."
    },
    {
        "question": "9) Этапы делинеаризации",
        "answer": "____\n1. Поиск общих элементов: Найдите части регулярного выражения, которые повторяются в альтернативных путях, и вынесите их за скобки. Например, в выражении abd|acd, можно вынести часть a и d, так как они повторяются в обеих альтернативных ветвях.\n2. Использование группировок: После нахождения общих элементов, сгруппируйте различающиеся части в выражении с помощью скобок. Это позволит вам сократить избыточные части выражения.\n3. Оптимизация повторений: Если в регулярном выражении присутствуют однотипные повторения символов или групп, используйте квантификаторы (*, +, {n} и другие), чтобы компактно выразить повторение."
    },
    {
        "question": "10) Преимущества делинеаризации",
        "answer": "____\n1. Улучшенная читаемость: Делинеаризованное выражение легче читать и понимать, так как оно отображает логику в более организованной форме.\n2. Меньший объем кода: После делинеаризации выражение часто становится короче, так как многие элементы можно вынести и сократить.\n3. Проще в модификации: Делинеаризованное регулярное выражение проще модифицировать и поддерживать, так как его структура лучше отражает логику проверки."
    },
    {
        "question": "11) Недостатки делинеаризации",
        "answer": "____\n1. Может усложнить понимание: В некоторых случаях слишком сложные группировки могут сделать регулярное выражение менее понятным, особенно для тех, кто не знаком с использованием квантификаторов и группировок.\n2. Не всегда применимо: Не каждое линейное выражение можно делинеаризовать эффективно. Если в выражении нет очевидных повторений или общих частей, попытка делинеаризации может не дать значительного улучшения."
    },
    {
        "question": "12) Формальные языки",
        "answer": "____\nФормальный язык — это множество M слов над алфавитом Σ(обозначается M ⊆ Σ∗, здесь знак ∗ — итерация Клини). Обычно подразумевает наличие формальных правил, определяющих корректность формы (т.е. синтаксиса) слов из M."
    },
    {
        "question": "13) Перечислимость и разрешимость формальных языков",
        "answer": "____\nЯзык M разрешимый ⇔ для любого слова w существует алгоритм проверки принадлежности w к M(всегда завершающийся и дающий точный, либо положительный, либо отрицательный ответ). \nЯзык M перечислимый ⇔ для любого слова w существует алгоритм, положительно отвечающий на вопрос принадлежности w к M за конечное время (но, возможно, зацикливающийся, если w /∈ M). \nПеречислимый, но не разрешимый: язык программ, завершающихся на входе 0 (на любом достаточно мощном ЯП). Далее разрешимые языки можно классифицировать по минимально необходимой сложности разрешающего алгоритма."
    },
    {
        "question": "14) Системы переписывания термов",
        "answer": "____\nСигнатура — множество пар ⟨f, n⟩ из имени конструктора f и его местности n.\nПусть V — множество переменных, F — множество конструкторов; множество термов T(F) над F определяется рекурсивно:\n1. все элементы V — термы;\n2. если ⟨f, n⟩ — конструктор и t_1,. . . , t_n — термы, то f(t_1, . . . , t_n) — терм;\n3. других термов нет.\n\nПусть V — множество переменных, F — множество конструкторов (сигнатура); T(F) — множество термов над множеством конструкторов F. TRS — набор правил переписывания вида Φ_i → Ψ_i, где Φ_i, Ψ_i — термы в T(F). Правило переписывания Φ_i → Ψ_i применимо к терму t, если t содержит подтерм, который можно сопоставить (унифицировать) с Φ_i.\n\nЕсли к терму t не применимо ни одно правило переписывания TRS, терм называется нормализованным. Имея правила переписывания вида f(g(x)) → g(g(f(x))) и g(g(x)) → f(x), каждое из них можно применить к терму f(g(g(f(g(f(g(g(g(Z))))))))) тремя разными способами."
    },
    {
        "question": "15) Конфлюэнтность",
        "answer": "____\nTRS называется конфлюэнтной, если для любых двух термов t, s, которые получаются переписыванием одного и того же терма u, существует терм v такой, что t, s оба переписываются в v.\nФормально:\n∀u, t, s(u →∗t & u →∗s ⇒ ∃v(t →∗ v & s →∗ v))\n\nКонфлюэнтные системы поддаются распараллеливанию и легко оптимизируются.\n→ — переписывание за 1 шаг;\n→∗ — переписывание за произвольное число шагов,\nначиная с 0."
    },
    {
        "question": "16) Синтаксический моноид",
        "answer": "____\nМоноид — это алгебраическая структура, состоящая из множества MM с бинарной операцией ⋅ (умножение), которая:\n1. ассоциативна: (a⋅b)⋅c=a⋅(b⋅c) для любых a, b ,c ∈ M;\n2. имеет единичный элемент e ∈ M, такой что для любого a ∈ M выполнено e⋅a=a⋅e =a.\n\nФакторизация по отношению к языку: Чтобы построить синтаксический моноид для языка, сначала определим отношение факторизации по отношению к языку L⊆Σ∗ (где Σ∗ — множество всех строк над алфавитом Σ).\n\nДве строки u и v считаются эквивалентными по отношению к языку L, если для всех строк x,y ∈ Σ∗ выполнение условия xuy ∈ L эквивалентно xvy ∈ L. Это эквивалентное отношение называется синтаксической эквивалентностью и обозначается u ∼_L v.\n\nСвязь с конечными автоматами:\nСинтаксический моноид можно использовать для описания регулярных языков. Для любого регулярного языка его синтаксический моноид является конечным, а язык можно распознать с помощью конечного автомата, построенного на основе этого моноида. Это означает, что синтаксический моноид является мощным инструментом для анализа структуры регулярных языков и их поведения.\n\nТеорема Микана: Язык является регулярным тогда и только тогда, когда его синтаксический моноид является конечным.\n\nПрименение:\n1. Классификация регулярных языков: Синтаксический моноид позволяет описывать регулярные языки с точки зрения алгебраической структуры. Это особенно полезно при анализе и классификации языков.\n2. Определение сложности языков: Сложность синтаксического моноида (например, количество его элементов) может дать представление о сложности описания языка.\n3. Минимизация конечных автоматов: Используя синтаксические моноиды, можно строить минимальные конечные автоматы, которые эффективно распознают регулярные языки."
    },
    {
        "question": "17) Построение синтаксического моноида",
        "answer": "____\nСинтаксический моноид можно построить следующим образом:\n1. Множество классов эквивалентности: Рассмотрим множество всех классов эквивалентности строк по отношению к синтаксической эквивалентности. Каждый класс эквивалентности строк соответствует одному элементу синтаксического моноида.\n2. Операция на классах эквивалентности: Пусть [u][u] и [v][v] — классы эквивалентности строк uu и vv соответственно. Тогда операция в синтаксическом моноиде определяется как [u]⋅[v]=[uv], где uv — конкатенация строк u и v.\n3. Единичный элемент: Единичным элементом синтаксического моноида является класс эквивалентности пустой строки ϵ, который обычно обозначается как [ϵ].\n\nТаким образом, синтаксический моноид состоит из всех классов эквивалентности строк по отношению к синтаксической эквивалентности с операцией конкатенации строк."
    },
    {
        "question": "Грамматика в нормальной форме Хомского это",
        "answer": "____\nГрамматикой в нормальной форме Хомского (англ. Chomsky normal form) называется контекстно-свободная грамматика, в которой могут содержаться правила только следующего вида:\nA→BC,\nA→a,\nS→ε,\nгде:\na — терминал, \nA,B,C — нетерминалы, \nS — стартовая вершина,\nε — пустая строка, стартовая вершина не содержится в правых частях правил."
    },
    {
        "question": "Докажи теорему: Любую контекстно-свободную грамматику можно привести к нормальной форме Хомского.",
        "answer": "____\nРассмотрим контекстно-свободную грамматику Γ. Для приведения ее к нормальной форме Хомского необходимо выполнить пять шагов. На каждом шаге мы строим новую Γi, которая допускает тот же язык, что и Γ.\n\nУберём длинные правила.\nВоспользуемся алгоритмом удаления длинных правил из грамматики. Получим грамматику Γ1, эквивалентную исходной, содержащую правила длины 0,1 и 2.\nУдаление ε - правил.\nВоспользуемся алгоритмом удаления ε - правил из грамматики. Получим грамматику Γ2, эквивалентную исходной, но в которой нет ε - правил.\nУдаление цепных правил.\nВоспользуемся алгоритмом удаления цепных правил из грамматики. Алгоритм работает таким образом, что новые ε - правила не образуются. Получим грамматику Γ3, эквивалентную Γ.\nУдалим бесполезные символы.\nВоспользуемся алгоритмом удаления бесполезных символов из грамматики. Так как Γ3\nэквивалентна Γ, то бесполезные символы не могли перестать быть бесполезными. Более того, мы только удаляем правила, новые ε-правила и цепные правила не могли появиться.\nУберём ситуации, когда в правиле встречаются несколько терминалов.\nДля всех правил вида A→u1u2\n(где ui — терминал или нетерминал) заменим все терминалы ui на новые нетерминалы Ui и добавим правила Ui→ui. \nТеперь правила содержат либо одиночный терминал, либо строку из двух нетерминалов.\nТаким образом, мы получили грамматику в нормальной форме Хомского, которая допускает тот же язык, что и Γ.\n\nСтоит заметить, что порядок выполнения операций важен. Первое правило должно быть выполнено перед вторым, иначе время нормализации ухудшится до O(2|Γ|). Третье правило идет после второго, потому что после удаления ε-правил, могут образоваться новые цепные правила. Также четвертое правило должно быть выполнено позже третьего и второго, так как они могут порождать бесполезные символы.\n\nПри таком порядке действий размеры грамматики возрастают полиномиально.\n\nПосле удалении длинных правил из каждого правила длины k⩾3 могло появиться k−1 новых правил, причем их длина не превышает двух. На этом шаге размер грамматики возрастает не более, чем вдвое.\n\nПри удалении ε-правил из грамматики, содержащей правила длины 0,1 и 2, размеры грамматики могли вырасти не больше, чем в 3 раза.\n\nВсего цепных правил в грамматике не больше, чем n2, где n — число нетерминалов. При удалении цепных правил мы берем каждую из цепных пар и производим добавление нецепных правил, выводимых из второго нетерминала в паре. Если максимальная суммарная длина всех правил, выводимых из какого-либо нетерминала, равна k, то размер грамматики возрастет не больше, чем на k⋅n2.\n\nНаконец, на последнем шаге может произойти добавление не более, чем |Σ|(Σ— алфавит грамматики) новых правил, причем все они будут длины 1."
    },
    {
        "question": "Грамматика в ослабленной нормальной форме Грейбах",
        "answer": "____\nГрамматикой в ослабленной нормальной форме Грейбах (англ. Greibach weak normal form) называется контекстно-свободная грамматика, в которой могут содержаться только правила одного из следующих типов:\nA→aγ\nS→ε\nгде a — терминал, A — нетерминал (возможно, стартовый), S — стартовый нетерминал (причём он не должен встречаться в правых частях правил), ε — пустая строка, γ — строка из произвольного числа терминалов и нетерминал"
    },
    {
        "question": "Докажи лемму об удалении терминалов:",
        "answer": "____\nКаждому терминалу a поставим в соотвествие новый символ a′, которого нет в N∪Σ, такой что a′≠b′ для разных терминалов a и b.\n\nПусть N′=N∪{a′∣a∈Σ}\n\nПусть α=x1x2…xn — часть правила, тогда α′=y1y2…yn, где yi={xix′i; xi∈N; xi∈Σ для 1⩽i⩽n.\n\nПостроим грамматику G′=⟨Σ,N′,S,P′⟩, где P′={α′→β′∣α→β∈P}∪{a′→a∣a∈Σ}\n\nПокажем, что L(Γ′)=L(Γ)\n\nПусть w∈L(Γ)\n Тогда в Γ существует вывод S=w0⇒w1⇒…⇒wn⇒w\n\nСогласно конструкции P′, в Γ′ существует вывод S=w′0⇒w′1⇒w′2⇒…⇒w′n=v0⇒v1⇒v2⇒…⇒vm=w\n\nДля 0⩽i⩽n−1 в переходах w′i⇒w′i+1 используем правило α′→β′, так как правило α→β было использовано при выводе wi⇒wi+1\n\nДля 0⩽j⩽m−1 в переходах vj⇒vj+1 используем правила вида a′→a\n\nЗаменяем разрешенные в w′ символы на новые и получаем, что w∈L(Γ′)\nТогда L(Γ)⊆L(Γ′)\n\n\nПусть x∈L(Γ′). Тогда в Γ′ существует вывод S⇒∗x\nМы можем поменять порядок применения правил в этом выводе: сначала применяем только правила вида α′→β′, а потом только правила вида a′→a.\n\nИз построения: после применения правила вида a′→a полученное a не может быть использовано при применении правил из P′\n\nИзменение порядка вывода не меняет язык, то есть в Γ′ существует вывод: S=x′0⇒x′1⇒…⇒x′r⇒x′⇒y1⇒y2⇒…⇒ys=x, где для 0⩽i⩽r−1 x′i+1∈(N′)∗ и в переходе x′i→x′i+1 было использовано правило вывода α′→β′ и для 1⩽j⩽s было использовано правило a′→a, чтобы получить yj→yj+1\n\nПолучаем вывод в Γ: S=x0⇒x1⇒…⇒xn=x\n\nТогда L(Γ′)⊆L(Γ)\n\nТаким образом, L(Γ′)=L(Γ)\n\nОчевидно, что если грамматика была неукорочивающейся, то она такой и останется."
    },
    {
        "question": "Лемма (об удалении коротких правил) доказательство",
        "answer": "____\nСначала по Γ построим грамматику Γ′′=⟨Σ,N′′,S,P′′⟩, как в доказательстве леммы 1. По Γ′′ построим грамматику Γ′, в которой:\n\nN′=N′′∪{D}, где D — новый символ, P′ получаем из P′′ заменой всех правил вида α→β∈P′′, где |α|>|β|, на правила вида α→βD|α|−|β|, и добавлением правила D→ε.\nТеперь все правила в P′ имеет требуемую форму.\n\nПокажем, что L(Γ′)=L(Γ)\n\nЗаметим, что замена правила α→β на α→βD|α|−|β| не меняет язык грамматики, потому что D переходит только в ε, а других правил для D нет.\n\nТогда получаем, что L(Γ)⊆L(Γ′), аналогично обратные изменения не меняют язык, то есть L(Γ′)⊆L(Γ)."
    },
    {
        "question": "Порядок грамматики",
        "answer": "____\nДля любой грамматики Γ=⟨Σ,N,S,P⟩ порядка n⩾3, такой что: любое правило из P′ имеет вид α→β, где α∈(N′)+ и β∈(N′)+ и |α|⩽|β| или A→a или A→ε, где A∈N′ и a∈T может быть построена грамматика Γ′=⟨Σ,N′,S,P′⟩ порядка n−1 такая, что L(Γ′)=L(Γ)"
    },
    {
        "question": "Мгновенное описание",
        "answer": "____\nМгновенное описание (англ. instantaneous descriptions) — это набор ⟨q,α,γ⟩, где q — текущее состояние, α — остаток строки, γ — содержимое стека."
    },
    {
        "question": "Детерминированный автомат с магазинной памятью",
        "answer": "____\nДетерминированным автоматом с магазинной памятью (англ. deterministic pushdown automaton) называется автомат с магазинной памятью, для которого выполнены следующие условия:\n8q∈Q,a∈Σ∪{ε},X∈Γ⇒δ(q,a,X) имеет не более одного элемента — δ:Q×Σ∪{ε}×Γ→Q×Γ∗\nЕсли δ(q,a,X) непусто для некоторого a∈Σ, то δ(q,ε,X) должно быть пустым."
    },
    {
        "question": "Детерминированный автомат с магазинной памятью, допуск по пустому стеку",
        "answer": "____\nОпределим детерминированный автомат с магазинной памятью, допускающий по пустому стеку (англ. PDA accepting by empty stack), как детерминированный автомат с магазинной памятью, у которого нет множества T допускающих состояний. Автомат заканчивает свою работу как только стек становится пустым.\nОпределим для него множество допускающих слов N={ω∣(q0,a0,Z0)⊢∗(p,ϵ,ϵ)}, где p — произвольное состояние."
    },
    {
        "question": "Правый контекст это",
        "answer": "____\nПравым контекстом (англ. right context) C_R_L(y) слова y в языке L называется множество {z∣yz∈L}"
    },
    {
        "question": "Левый контекст это",
        "answer": "____\nЛевым контекстом (англ. left context) C_L_L(y) слова y в языке L называется множество {z∣zy∈L}"
    },
    {
        "question": "Двухсторонний контекст это",
        "answer": "____\nДвухсторонним контекстом (англ. two-sided context) C_L(y) слова y в языке L называется множество {⟨x,z⟩∣xyz∈L}"
    },
    {
        "question": "4. Конструкция автомата Глушкова.",
        "answer": "____\nАлгоритм построения Glushkov(r)\n1. Строим линеаризованную версию r: r(Lin) = Linearize(r).\n2. Ищем First(r(Lin)), Last(r(Lin)) и Follow(r(Lin))(c) для всех\nc принадлежащих (Сумма(r(Lin))) .\n3. Все состояния автомата, кроме начального (назовём его S),\nсоответствуют буквам c принадлежит (Сумма(r(Lin))) .\n4. Из начального состояния строим переходы в те состояния,\nдля которых c принадлежит First(r(Lin)). Переходы имеют вид S -> c по с.\n5. Переходы из состояния c соответствуют элементам d\nмножества Follow(r(Lin))(c) и имеют вид c -> d по d.\n6. Конечные состояния — такие, что c принадлежит Last(r(Lin)), а также S,\nесли эпсилон принадлежит L(R).\n7. Теперь стираем разметку, построенную линеаризацией, на\nпереходах автомата. Конструкция завершена."
    }
]